{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:06:04.915824Z",
     "start_time": "2022-09-19T07:06:03.098371Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.cluster import KMeans, DBSCAN, MeanShift, estimate_bandwidth\n",
    "import itertools\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering of Merchants\n",
    "### **Objective**: Perform a hard clustering on the merchants to obtain 3 to 5 clusters, which can be used for market segmentation.\n",
    "### **Overview**: In this notebook, we aim to uncover some underlying cluster structure of our candidate merchant based on three engineered features (as listed below). These features are essential metrics for quantifying the business scale of a merchant, as we believe that not only the merchants with high volume of orders and customers but also small merchants should be given an opportunity to enlarge their business through availability of BNPL service for customers.\n",
    "### **Attributes for clustering**:\n",
    "   1. total_number_of_distinct_customers:\n",
    "   2. monthly_average_number_of_orders:\n",
    "   3. monthly_average_bnpl_revenue:\n",
    "### **Clustering pipeline**:\n",
    " 0. Preliminary Data Analysis\n",
    " 1. Data Clustering\n",
    "    1. K-means\n",
    "    2. MeanShift\n",
    "    3. DBSCAN\n",
    "    4. Gaussian Mixture Model\n",
    " 2. Clustering Evaluation\n",
    "    1. Silhouette Coefficient\n",
    "    2. Calinski-Harabasz Index\n",
    "    3. Davies-Bouldin Index\n",
    " 3. Clustering Model Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:06:04.954723Z",
     "start_time": "2022-09-19T07:06:04.918824Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "merchant_df = pd.read_csv(\"../data/curated/clusters/input/agg_transaction_train.csv\")\n",
    "merchant_df = merchant_df[[\"merchant_abn\",\n",
    "                           \"total_number_of_distinct_customers\",\n",
    "                           \"monthly_average_number_of_orders\",\n",
    "                           \"monthly_average_bnpl_revenue\",\n",
    "                           \"take_rate\"\n",
    "                           ]]\n",
    "merchant_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PDA**\n",
    "#### 1. The binary correlations between the three attributes are good, no multi-collinearity exists.\n",
    "#### 2. As we can see that the distributions of the three attributes are very right-skewed, which can potentially lead to clusters that are too uneven in size. Therefore, log transformations will be beneficial to unskew the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features = [\n",
    "            \"monthly_average_bnpl_revenue\",\n",
    "            \"monthly_average_number_of_orders\",\n",
    "            \"total_number_of_distinct_customers\"\n",
    "            ]\n",
    "\n",
    "X = merchant_df[features]\n",
    "\n",
    "X.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:06:06.252105Z",
     "start_time": "2022-09-19T07:06:04.957613Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (12, 4), dpi = 100)\n",
    "for i in range(len(features)):\n",
    "    sns.histplot(merchant_df[features[i]], \n",
    "                stat = 'probability', \n",
    "                bins=50,\n",
    "                ax = ax[i])\n",
    "\n",
    "\n",
    "# It seems that we can perform GMM on log(features)\n",
    "fig, ax = plt.subplots(1, 3, figsize = (14, 4), dpi = 100)\n",
    "for i in range(len(features)):\n",
    "    sns.histplot(merchant_df[features[i]].apply(np.log), \n",
    "                stat = 'probability', \n",
    "                bins=50,\n",
    "                ax = ax[i])\n",
    "    ax[i].set_xlabel(f'log({ax[i].get_xlabel()})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:06:06.261701Z",
     "start_time": "2022-09-19T07:06:06.254416Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "log_X = X.apply(np.log)\n",
    "\n",
    "def homemade_GridSearch(model, parameters, data):\n",
    "    \"\"\"\n",
    "    return a dataframe showing the gridsearch result\n",
    "    parameters:\n",
    "               model: a sklearn model\n",
    "               parameters: a dictionary of parameters for the model, each parameter is a list of possible value\n",
    "               data: the dataset to fit\n",
    "    return:\n",
    "           a dataframe which shows the performance of all combinations of parameters\n",
    "    \"\"\"\n",
    "    # Name of the parameters\n",
    "    parameter_names = list(parameters.keys())\n",
    "    # Evaluation metrics\n",
    "    eval_metrics = [silhouette_score, davies_bouldin_score, calinski_harabasz_score]\n",
    "    # Name of the evaluation metrics\n",
    "    eval_metric_names = ['silhouette_score', 'davies_bouldin_score', 'calinski_harabasz_score']\n",
    "\n",
    "    # Store the performance in a dict\n",
    "    performance_dict = {parameter: [] for parameter in parameter_names + eval_metric_names + [\"num_clusters\"]}\n",
    "\n",
    "    for parameter_value in tqdm(itertools.product(*map(parameters.get, list(parameter_names)))):\n",
    "        # Store the combination of parameters in a dict\n",
    "        parameter_set = dict(zip(parameter_names, parameter_value))\n",
    "        labels = model.set_params(**parameter_set).fit_predict(data)\n",
    "        # Store the parameters and corresponding score\n",
    "        for parameter_name in parameter_names:\n",
    "            performance_dict[parameter_name].append(parameter_set[parameter_name])\n",
    "        for eval_metric_name, eval_metric in zip(eval_metric_names, eval_metrics):\n",
    "            try:\n",
    "                score = eval_metric(data, labels)\n",
    "            except:\n",
    "                # If score cannot be calculated, return NaN\n",
    "                score = np.nan\n",
    "            performance_dict[eval_metric_name].append(score)\n",
    "       \n",
    "        # Add an additional column indicating the number of clusters\n",
    "        performance_dict[\"num_clusters\"].append(len(np.unique(labels)))\n",
    "\n",
    "    return pd.DataFrame(performance_dict)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:06:07.581898Z",
     "start_time": "2022-09-19T07:06:06.263514Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "k_mean_params = {\n",
    "    'n_clusters': [3, 4, 5],\n",
    "    'random_state': [2022, ]\n",
    "}\n",
    "\n",
    "display(homemade_GridSearch(KMeans(), k_mean_params, X))\n",
    "homemade_GridSearch(KMeans(), k_mean_params, log_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:07:32.227702Z",
     "start_time": "2022-09-19T07:06:07.584344Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "mean_shift_params1 = {\n",
    "     'bandwidth': [estimate_bandwidth(X, quantile=q) for q in np.linspace(0.00099, 0.9999, num=10)]\n",
    "     }\n",
    "\n",
    "mean_shift_params2 = {\n",
    "     'bandwidth': [estimate_bandwidth(log_X, quantile=q) for q in np.linspace(0.00099, 0.9999, num=10)]\n",
    "     }\n",
    "\n",
    "display(homemade_GridSearch(MeanShift(), mean_shift_params1, X).query(\"num_clusters <= 5 & num_clusters >= 3\"))\n",
    "homemade_GridSearch(MeanShift(), mean_shift_params2, log_X).query(\"num_clusters <= 5 & num_clusters >= 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:07:52.592236Z",
     "start_time": "2022-09-19T07:07:32.230890Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dbscan_params1 = {\n",
    "    'eps': [10, 100, 1000, 5000, 10000, 50000, 100000],\n",
    "    'min_samples': [1, 5, 10, 20, 50, 100, 500, 1000]\n",
    "}\n",
    "dbscan_params2 = {\n",
    "    'eps': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples': [1, 5, 10, 20, 50, 100, 500, 1000]\n",
    "}\n",
    "\n",
    "display(homemade_GridSearch(DBSCAN(), dbscan_params1, X).query(\"num_clusters <= 5 & num_clusters >= 3\"))\n",
    "homemade_GridSearch(DBSCAN(), dbscan_params2, log_X).query(\"num_clusters <= 5 & num_clusters >= 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:07:59.366548Z",
     "start_time": "2022-09-19T07:07:52.595894Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gmm_params = {\n",
    "    'n_components': [3, 4, 5],\n",
    "    'init_params': ['kmeans', 'random'],\n",
    "    'random_state': [2022, ]\n",
    "}\n",
    "\n",
    "display(homemade_GridSearch(GaussianMixture(), gmm_params, X))\n",
    "homemade_GridSearch(GaussianMixture(), gmm_params, log_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-19T07:10:08.916009Z",
     "start_time": "2022-09-19T07:10:08.032341Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "def visualize_cluster(model, data, figname):\n",
    "    \"\"\"\n",
    "    return a figure of clusters\n",
    "    \"\"\"\n",
    "    data_copy = data.copy()\n",
    "\n",
    "    # Define X, Y and Z axes\n",
    "    xs = data_copy[features[0]]\n",
    "    ys = data_copy[features[1]]\n",
    "    zs = data_copy[features[2]]\n",
    "    \n",
    "    # Clusters of the data\n",
    "    data_copy[\"cluster\"] = model.fit_predict(data_copy)\n",
    "\n",
    "    # Create a figure\n",
    "    figure = plt.figure(dpi = 100)\n",
    "    ax = figure.add_subplot(projection='3d')\n",
    "    ax.scatter(xs, ys, zs, c=data_copy[\"cluster\"])\n",
    "\n",
    "    ax.set_title(figname)\n",
    "    ax.set_xlabel(features[0])\n",
    "    ax.set_ylabel(features[1])\n",
    "    ax.set_zlabel(features[2])\n",
    "    \n",
    "    return figure\n",
    "\n",
    "fg1 = visualize_cluster(KMeans(n_clusters=3), log_X, \"Kmean Clustering of logX\")\n",
    "fg2 = visualize_cluster(GaussianMixture(n_components=3, init_params='kmeans'), log_X, \"GMM Clustering of logX\")\n",
    "fg3 = visualize_cluster(DBSCAN(eps=10000, min_samples=10), X, \"DBSCAN Clustering of X\")\n",
    "fg4 = visualize_cluster(MeanShift(bandwidth=1.984250), log_X, \"MeanShift Clustering of logX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mKernel Python 3.10.2 64-bit is not usable. Check the Jupyter output tab for more information. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Final clustering model\n",
    "gmm = GaussianMixture(n_components=3, init_params='kmeans').fit(X)\n",
    "merchant_df[\"label\"] = gmm.predict(X)\n",
    "\n",
    "# Predict the cluster of the unknown merchants \n",
    "pred = pd.read_csv(\"../data/curated/clusters/input/agg_transaction_pred.csv\")\n",
    "pred[\"label\"] = gmm.predict(pred[features].apply(np.log))\n",
    "pd.concat([merchant_df[[\"merchant_abn\", \"label\"]], pred[[\"merchant_abn\", \"label\"]]]) \\\n",
    "  .to_csv(\"../data/curated/clusters/output/merchant_clusters.csv\", index=False)\n",
    "\n",
    "\n",
    "# Fill missing take rate with cluster mean\n",
    "merchant_df.groupby(\"label\", as_index=False)[\"take_rate\"].mean().to_csv(\"../data/curated/clusters/output/take_rate.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
