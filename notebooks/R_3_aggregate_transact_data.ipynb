{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate data for first 3 variables of final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from gettext import npgettext\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/14 20:15:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# setup spark\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"aggregate data for first 3 final model variables\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data1 = spark.read.parquet(\"../data/tables/transactions_20210228_20210827_snapshot/\")\n",
    "data2 = spark.read.parquet(\"../data/tables/transactions_20210828_20220227_snapshot/\")\n",
    "data3 = spark.read.parquet(\"../data/tables/transactions_20220228_20220828_snapshot/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1.union(data2)\n",
    "data = data.union(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some new columns\n",
    "data = data.withColumn(\"Week\", F.weekofyear(\"order_datetime\"))\\\n",
    "        .withColumn(\"Year\", F.year(\"order_datetime\"))\\\n",
    "        .withColumn(\"Month\", F.month(\"order_datetime\"))\\\n",
    "        .withColumn(\"Day\", F.dayofmonth(\"order_datetime\"))\\\n",
    "        .withColumn(\"Fortnight\", ((F.col(\"Week\")+1)/2).cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>user_id</th><th>merchant_abn</th><th>dollar_value</th><th>order_id</th><th>order_datetime</th><th>Week</th><th>Year</th><th>Month</th><th>Day</th><th>Fortnight</th></tr>\n",
       "<tr><td>18478</td><td>62191208634</td><td>63.255848959735246</td><td>949a63c8-29f7-4ab...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>2</td><td>15549624934</td><td>130.3505283105634</td><td>6a84c3cf-612a-457...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18479</td><td>64403598239</td><td>120.15860593212783</td><td>b10dcc33-e53f-425...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>3</td><td>60956456424</td><td>136.6785200286976</td><td>0f09c5a5-784e-447...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18479</td><td>94493496784</td><td>72.96316578355305</td><td>f6c78c1a-4600-4c5...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>3</td><td>76819856970</td><td>448.529684285612</td><td>5ace6a24-cdf0-4aa...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18479</td><td>67609108741</td><td>86.4040605836911</td><td>d0e180f0-cb06-42a...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>3</td><td>34096466752</td><td>301.5793450525113</td><td>6fb1ff48-24bb-4f9...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18482</td><td>70501974849</td><td>68.75486276223054</td><td>8505fb33-b69a-412...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>4</td><td>49891706470</td><td>48.89796461900801</td><td>ed11e477-b09f-4ae...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18482</td><td>46804135891</td><td>6.6168976971833615</td><td>05b5edb5-b925-414...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>7</td><td>33064796871</td><td>373.0873675184212</td><td>fe188788-b89f-4dd...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18483</td><td>44160392990</td><td>83.98473054761176</td><td>7c44302d-98b3-48b...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>7</td><td>68435002949</td><td>232.5364986739752</td><td>b4a89891-a113-45e...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18484</td><td>70033549200</td><td>871.7678061729196</td><td>4b1d941a-21a1-43e...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>7</td><td>41944909975</td><td>30.910755230234322</td><td>302ae628-8eba-4a5...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18485</td><td>41705715409</td><td>309.5417224575787</td><td>67f4f98e-3149-4e8...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>8</td><td>29566626791</td><td>74.15732460440282</td><td>71a81652-cc91-4bf...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>18487</td><td>32361057556</td><td>119.19055863068847</td><td>15577921-1104-470...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "<tr><td>9</td><td>47663262928</td><td>36.69873283148887</td><td>c4fcb49a-ce87-4e1...</td><td>2021-08-20</td><td>33</td><td>2021</td><td>8</td><td>20</td><td>17</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------+------------+------------------+--------------------+--------------+----+----+-----+---+---------+\n",
       "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|Week|Year|Month|Day|Fortnight|\n",
       "+-------+------------+------------------+--------------------+--------------+----+----+-----+---+---------+\n",
       "|  18478| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      2| 15549624934| 130.3505283105634|6a84c3cf-612a-457...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18479| 64403598239|120.15860593212783|b10dcc33-e53f-425...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      3| 60956456424| 136.6785200286976|0f09c5a5-784e-447...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18479| 94493496784| 72.96316578355305|f6c78c1a-4600-4c5...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      3| 76819856970|  448.529684285612|5ace6a24-cdf0-4aa...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18479| 67609108741|  86.4040605836911|d0e180f0-cb06-42a...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      3| 34096466752| 301.5793450525113|6fb1ff48-24bb-4f9...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18482| 70501974849| 68.75486276223054|8505fb33-b69a-412...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      4| 49891706470| 48.89796461900801|ed11e477-b09f-4ae...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18482| 46804135891|6.6168976971833615|05b5edb5-b925-414...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      7| 33064796871| 373.0873675184212|fe188788-b89f-4dd...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18483| 44160392990| 83.98473054761176|7c44302d-98b3-48b...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      7| 68435002949| 232.5364986739752|b4a89891-a113-45e...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18484| 70033549200| 871.7678061729196|4b1d941a-21a1-43e...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      7| 41944909975|30.910755230234322|302ae628-8eba-4a5...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18485| 41705715409| 309.5417224575787|67f4f98e-3149-4e8...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      8| 29566626791| 74.15732460440282|71a81652-cc91-4bf...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|  18487| 32361057556|119.19055863068847|15577921-1104-470...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "|      9| 47663262928| 36.69873283148887|c4fcb49a-ce87-4e1...|    2021-08-20|  33|2021|    8| 20|       17|\n",
       "+-------+------------+------------------+--------------------+--------------+----+----+-----+---+---------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop dates that don't make a full week at start and end\n",
    "data = data.filter(data[\"order_datetime\"] >= F.lit('2021-03-01')) \\\n",
    "       .filter(data[\"order_datetime\"] <= F.lit('2022-08-14'))\n",
    "data\n",
    "\n",
    "## ONE THOUGHT: START THE WEEK ON A SUNDAY... but how does it affect the cycle? domain knowledge\n",
    "\n",
    "## THEORY: create a new column that is 1 day later than current date, and then take weekofyear based on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12157084"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by week and fortnight; retain sum of transactions, number of customers, number of transactions\n",
    "transact_agg_by_comp_week = data.groupBy(\"Year\", \"Week\", \"merchant_abn\")\\\n",
    "        .agg(F.sum(\"dollar_value\")\\\n",
    "        .alias(\"sum_transactions\"), \\\n",
    "         F.count(\"order_id\").alias(\"number_of_customers\"), \\\n",
    "         F.countDistinct(\"user_id\").alias(\"distinct_customers\"))\n",
    "\n",
    "\n",
    "transact_agg_by_comp_fortnight = data.groupBy(\"Year\", \"Fortnight\", \"merchant_abn\")\\\n",
    "        .agg(F.sum(\"dollar_value\")\\\n",
    "        .alias(\"sum_transactions\"), \\\n",
    "         F.count(\"order_id\").alias(\"number_of_customers\"), \\\n",
    "         F.countDistinct(\"user_id\").alias(\"distinct_customers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# turn both into pandas dataframe\n",
    "transact_agg_comp_week_df = transact_agg_by_comp_week.toPandas()\n",
    "\n",
    "transact_agg_comp_fortnight_df = transact_agg_by_comp_fortnight.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263758"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_week_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145859"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fill_na_df(transact_agg_comp_period_df, period):\n",
    "    \"\"\" helper function to create dataframe of all combos and 0 value for fillup \"\"\"\n",
    "\n",
    "    ## Fill up na\n",
    "    # get set of merchants\n",
    "    distinct_merchants = set(transact_agg_comp_period_df.merchant_abn)\n",
    "\n",
    "    # get set of year and period\n",
    "    year_period_set = list()\n",
    "\n",
    "    for id, dta in transact_agg_comp_period_df.groupby(['Year', period]):\n",
    "        year_period_set.append(id)\n",
    "\n",
    "    year_period_set = year_period_set[:-1]\n",
    "\n",
    "    years = [x[0] for x in year_period_set]\n",
    "    periods = [x[1] for x in year_period_set]\n",
    "\n",
    "    # make dataframes and join up\n",
    "    fill_na_time = pd.DataFrame({\"Year\": years, period: periods})\n",
    "\n",
    "    fill_na_companies = pd.DataFrame({\"merchant_abn\": list(distinct_merchants)})\n",
    "\n",
    "    fill_na_df = fill_na_time.merge(fill_na_companies, how = 'cross')\n",
    "\n",
    "    for col in transact_agg_comp_week_df.columns[3:]:\n",
    "        fill_na_df[col] = 0\n",
    "\n",
    "    return fill_na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_stray_period(transact_agg_comp_period_df, period):\n",
    "        \"\"\" correct problem of first few days of 2022 classified as wk 52 or fortnight 26, \n",
    "        which under our aggregation becomes separate week of 2022 week 52 or fortnight 26 \"\"\"\n",
    "\n",
    "        # figure out what the stray period number is\n",
    "        if period == 'Week':\n",
    "                stray_period_id = 52\n",
    "        else:\n",
    "                stray_period_id = 26\n",
    "\n",
    "        # take out just the stray period data\n",
    "        stray_period = transact_agg_comp_period_df[(transact_agg_comp_period_df[period] == stray_period_id) & \n",
    "                (transact_agg_comp_period_df['Year'] == 2022)]\n",
    "\n",
    "        transact_agg_comp_period_df = transact_agg_comp_period_df.drop(stray_period.index)\n",
    "\n",
    "        # update the stray period data's year\n",
    "        stray_period['Year'] = stray_period['Year']-1\n",
    "        # put it back\n",
    "        transact_agg_comp_period_df = pd.concat([transact_agg_comp_period_df, stray_period])\n",
    "\n",
    "        return transact_agg_comp_period_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(transact_agg_comp_period_df, fill_na_df, period):\n",
    "    \"\"\" Helper function to fill na \"\"\"\n",
    "    \n",
    "    transact_agg_comp_period_filled_df = pd.concat([transact_agg_comp_period_df, fill_na_df])\n",
    "    transact_agg_comp_period_filled_df = transact_agg_comp_period_filled_df.groupby(['Year', period, 'merchant_abn'])\\\n",
    "        .agg({'sum_transactions': sum, 'number_of_customers': sum, 'distinct_customers': sum})\n",
    "    transact_agg_comp_period_filled_df = transact_agg_comp_period_filled_df.reset_index()\n",
    "\n",
    "    return transact_agg_comp_period_filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prestart_filled_weeks(transact_agg_comp_period_filled_df, period): \n",
    "    \"\"\" Helper function to clean out wrongly filled 0 weeks (which will distort mean and variance) \"\"\"\n",
    "\n",
    "    # remove weeks before first BNPL transaction\n",
    "    transact_agg_comp_period_filled_adjusted_df = pd.DataFrame()\n",
    "\n",
    "    for id, dta in transact_agg_comp_period_filled_df.groupby(['merchant_abn']):\n",
    "        \n",
    "        # iterate down the rows, and drop rows until first row where there is non0 transaction value\n",
    "        dta = dta.sort_values(['Year', period])\n",
    "\n",
    "        for row in dta.iterrows(): \n",
    "            if row[1][5] == 0: # if row's transaction value = 0\n",
    "                dta = dta.drop(row[0])\n",
    "            \n",
    "            else:\n",
    "                break\n",
    "\n",
    "        transact_agg_comp_period_filled_adjusted_df = pd.concat([transact_agg_comp_period_filled_df, dta])\n",
    "\n",
    "    return transact_agg_comp_period_filled_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transactions_agg_by_period(transact_agg_comp_period_df, period):\n",
    "    \"\"\" ETL function that runs all helpers to clean the aggregated merchant transaction data \"\"\"\n",
    "\n",
    "    fill_na_df = get_fill_na_df(transact_agg_comp_period_df, period)\n",
    "\n",
    "    transact_agg_comp_period_df = correct_stray_period(transact_agg_comp_period_df, period)\n",
    "\n",
    "    transact_agg_comp_period_filled_df = fill_na(transact_agg_comp_period_df, fill_na_df, period)\n",
    "\n",
    "    transact_agg_comp_period_filled_adjusted_df = remove_prestart_filled_weeks(transact_agg_comp_period_filled_df, period)\n",
    "\n",
    "    return transact_agg_comp_period_filled_adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_20261/327811925.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  stray_period['Year'] = stray_period['Year']-1\n"
     ]
    }
   ],
   "source": [
    "transact_agg_comp_week_filled_adjusted_df = get_transactions_agg_by_period(transact_agg_comp_week_df, 'Week')\n",
    "\n",
    "transact_agg_comp_fortnight_filled_adjusted_df = get_transactions_agg_by_period(transact_agg_comp_fortnight_df, 'Fortnight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_agg_comp_week_filled_adjusted_df.to_csv('../data/curated/final_model/weekly_agg_merchant_transactions.csv', index=False)\n",
    "\n",
    "transact_agg_comp_fortnight_filled_adjusted_df.to_csv('../data/curated/final_model/fortnightly_agg_merchant_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331841"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_week_filled_adjusted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168032"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transact_agg_comp_fortnight_filled_adjusted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect how many merchants have less than i weeks on record\n",
    "\n",
    "# nweeks = transact_agg_comp_week_df.groupby(['merchant_abn']).agg({'Week': 'count'})\n",
    "\n",
    "# print(\"Number of merchants with less than i weeks of activity\")\n",
    "# for i in range(20):\n",
    "\n",
    "#     print(i, len(nweeks[nweeks['Week']<= i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nperiods_and_drop_low_counts(transact_agg_comp_periods_df, period, low_counts=2):\n",
    "    \"\"\" get nperiod values and also drop merchants that don't have enough periods of records \"\"\"\n",
    "\n",
    "    # get number of periods with observed data per merchant\n",
    "    n_periods = transact_agg_comp_periods_df.groupby(['merchant_abn']).agg({period: 'count'})\n",
    "    n_periods = n_periods.rename(columns = {period: 'n_periods'})\n",
    "\n",
    "    # get list of low count abns and drop\n",
    "    low_count_merchants = n_periods[n_periods['n_periods'] <= low_counts].index\n",
    "\n",
    "    for abn in list(low_count_merchants):\n",
    "        transact_agg_comp_periods_df = transact_agg_comp_periods_df[transact_agg_comp_periods_df['merchant_abn'] != abn]\n",
    "\n",
    "    return transact_agg_comp_periods_df, n_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sd_nperiods(transact_agg_comp_week_df, n_periods):\n",
    "     \"\"\" Helper to get mean, sd and nperiods of merchants \"\"\"\n",
    "\n",
    "     # create replicate column to allow for two aggregations on the same column of data\n",
    "     transact_agg_comp_week_df['sum_transactions2'] = transact_agg_comp_week_df['sum_transactions']\n",
    "     mean_sd = transact_agg_comp_week_df.groupby(['merchant_abn']).agg({'sum_transactions': mean, 'sum_transactions2': stdev})\n",
    "\n",
    "     mean_sd = mean_sd.rename(columns = {'sum_transactions': 'mean',\\\n",
    "          'sum_transactions2': 'stdev'})\n",
    "\n",
    "     mean_sd = mean_sd.reset_index()\n",
    "     \n",
    "     mean_sd_nperiods = mean_sd.merge(n_periods, on = ['merchant_abn'], how = 'inner')\n",
    "\n",
    "     return mean_sd_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merchant_mean_sd_nperiods(transact_agg_comp_periods_df, period, low_counts = 2):\n",
    "    \"\"\" Function that runs helpers to get the merchant data in mean, sd and nperiods \"\"\"\n",
    "\n",
    "    transact_agg_comp_periods_df, n_periods = get_nperiods_and_drop_low_counts(transact_agg_comp_periods_df, period, low_counts)\n",
    "\n",
    "    mean_sd_nperiods = get_mean_sd_nperiods(transact_agg_comp_week_df, n_periods)\n",
    "\n",
    "    return mean_sd_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_nperiods_week = get_merchant_mean_sd_nperiods(transact_agg_comp_week_filled_adjusted_df, 'Week', low_counts = 2)\n",
    "mean_sd_nperiods_fortnight = get_merchant_mean_sd_nperiods(transact_agg_comp_fortnight_filled_adjusted_df, 'Fortnight', low_counts = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market(transact_agg_comp_period_df, period):\n",
    "    \"\"\" get the sum of all merchants data by period \"\"\"\n",
    "\n",
    "    market = transact_agg_comp_period_df.groupby(['Year', period])\\\n",
    "        .agg({'sum_transactions': sum, 'number_of_customers': 'count', 'distinct_customers': lambda x: x.nunique()})\n",
    "\n",
    "    market = market.reset_index()\n",
    "\n",
    "    return market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_mean_and_sd(market):\n",
    "    \"\"\" get the mean and sd of the market \"\"\"\n",
    "\n",
    "    market_mean = mean(market['sum_transactions'])\n",
    "    market_sd = stdev(market['sum_transactions'])\n",
    "\n",
    "    return market_mean, market_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_and_stats(transact_agg_comp_period_df, period):\n",
    "\n",
    "    market = get_market(transact_agg_comp_period_df, period)\n",
    "\n",
    "    market_mean, market_sd = get_market_mean_and_sd(market)\n",
    "\n",
    "    return market, market_mean, market_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_week, market_mean_week, market_sd_week = get_market_and_stats(transact_agg_comp_week_df, 'Week')\n",
    "\n",
    "market_fortnight, market_mean_fortnight, market_sd_fortnight = get_market_and_stats(transact_agg_comp_fortnight_df, 'Fortnight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_week.to_csv('../data/curated/final_model/market-all_by_week.csv', index=False)\n",
    "\n",
    "market_fortnight.to_csv('../data/curated/final_model/market-all_by_fortnight.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {'Week': {'mean': market_mean_week, 'sd': market_sd_week}, \\\n",
    "    'Fortnight': {'mean': market_mean_fortnight, 'sd': market_sd_fortnight}}\n",
    "\n",
    "Data = json.dumps(str(json_data))\n",
    "\n",
    "with open('../data/curated/final_model/Market_stats.json', 'w') as f:\n",
    "    json.dump(Data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_df(transact_agg_comp_period_df, market, period):\n",
    "    \"\"\" get dataframe of correlations \"\"\"\n",
    "\n",
    "    merchant_abns = list()\n",
    "    corr = list()\n",
    "\n",
    "    # get each abn's periodic data, left join on market, and then get correlation\n",
    "    for abn in list(set(transact_agg_comp_period_df['merchant_abn'])):\n",
    "        merchant = transact_agg_comp_period_df[transact_agg_comp_period_df['merchant_abn'] == abn]\n",
    "\n",
    "        merchant_market = merchant.merge(market, how = 'left', on = ['Year', period])\n",
    "        merchant_abns.append(abn)\n",
    "        corr.append(np.corrcoef(merchant_market['sum_transactions_x'], merchant_market['sum_transactions_y'])[0][1])\n",
    "\n",
    "    corr_df = pd.DataFrame({'merchant_abn': merchant_abns, 'corr': corr})\n",
    "\n",
    "    return corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sd_corr_nperiods(mean_sd_nperiods, corr_df, market_sd):\n",
    "    \"\"\" add corr and corr related variables to mean, sd dataframe \"\"\"\n",
    "\n",
    "    mean_sd_corr_nperiods = mean_sd_nperiods.merge(corr_df, on = ['merchant_abn'], how = 'inner')\n",
    "    mean_sd_corr_nperiods['covar'] = mean_sd_corr_nperiods['stdev'] * mean_sd_corr_nperiods['corr'] * market_sd\n",
    "    mean_sd_corr_nperiods['beta'] = mean_sd_corr_nperiods['covar']/(np.power(market_sd,2))\n",
    "    \n",
    "    return mean_sd_corr_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr(transact_agg_comp_period_df, market, period, mean_sd_nperiods, market_sd):\n",
    "    \n",
    "    corr_df = get_corr_df(transact_agg_comp_period_df, market, period)\n",
    "\n",
    "    mean_sd_corr_nperiods = get_mean_sd_corr_nperiods(mean_sd_nperiods, corr_df, market_sd)\n",
    "\n",
    "    return mean_sd_corr_nperiods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "mean_sd_corr_nperiods_week = get_corr(transact_agg_comp_week_df, market_week, \\\n",
    "    'Week', mean_sd_nperiods_week, market_sd_week)\n",
    "mean_sd_corr_nperiods_fortnight = get_corr(transact_agg_comp_fortnight_df, market_fortnight, \\\n",
    "    'Fortnight', mean_sd_nperiods_fortnight, market_sd_fortnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sd_corr_nperiods_week.to_csv('../data/curated/final_model/agg_weekly_mean_sd_marketcorr.csv', index=False)\n",
    "mean_sd_corr_nperiods_fortnight.to_csv('../data/curated/final_model/agg_fortnightly_mean_sd_marketcorr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>corr</th>\n",
       "      <th>covar</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6820.889570</td>\n",
       "      <td>2664.480345</td>\n",
       "      <td>0.347603</td>\n",
       "      <td>6.125052e+09</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13492.039026</td>\n",
       "      <td>4048.940496</td>\n",
       "      <td>0.314924</td>\n",
       "      <td>1.493482e+10</td>\n",
       "      <td>0.000538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>122.235276</td>\n",
       "      <td>67.364259</td>\n",
       "      <td>-0.999700</td>\n",
       "      <td>-8.880839e+10</td>\n",
       "      <td>-0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>752.050987</td>\n",
       "      <td>477.289633</td>\n",
       "      <td>0.141162</td>\n",
       "      <td>3.141869e+08</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2396.810028</td>\n",
       "      <td>1250.690582</td>\n",
       "      <td>0.349894</td>\n",
       "      <td>1.697796e+09</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8446.905268</td>\n",
       "      <td>3177.137782</td>\n",
       "      <td>0.595043</td>\n",
       "      <td>7.674692e+09</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109458.201106</td>\n",
       "      <td>44378.120027</td>\n",
       "      <td>0.999227</td>\n",
       "      <td>1.228957e+11</td>\n",
       "      <td>0.004429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean         stdev      corr         covar      beta\n",
       "mean    6820.889570   2664.480345  0.347603  6.125052e+09  0.000221\n",
       "std    13492.039026   4048.940496  0.314924  1.493482e+10  0.000538\n",
       "min      122.235276     67.364259 -0.999700 -8.880839e+10 -0.003200\n",
       "25%      752.050987    477.289633  0.141162  3.141869e+08  0.000011\n",
       "50%     2396.810028   1250.690582  0.349894  1.697796e+09  0.000061\n",
       "75%     8446.905268   3177.137782  0.595043  7.674692e+09  0.000277\n",
       "max   109458.201106  44378.120027  0.999227  1.228957e+11  0.004429"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sd_corr_nperiods_week.describe().drop(['merchant_abn', 'n_periods'], axis=1)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>corr</th>\n",
       "      <th>covar</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6820.889570</td>\n",
       "      <td>2664.480345</td>\n",
       "      <td>0.481387</td>\n",
       "      <td>1.919647e+10</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13492.039026</td>\n",
       "      <td>4048.940496</td>\n",
       "      <td>0.365678</td>\n",
       "      <td>4.245542e+10</td>\n",
       "      <td>0.000263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>122.235276</td>\n",
       "      <td>67.364259</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.127961e+11</td>\n",
       "      <td>-0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>752.050987</td>\n",
       "      <td>477.289633</td>\n",
       "      <td>0.230151</td>\n",
       "      <td>1.281612e+09</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2396.810028</td>\n",
       "      <td>1250.690582</td>\n",
       "      <td>0.513409</td>\n",
       "      <td>5.983286e+09</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8446.905268</td>\n",
       "      <td>3177.137782</td>\n",
       "      <td>0.802041</td>\n",
       "      <td>2.531106e+10</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109458.201106</td>\n",
       "      <td>44378.120027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.158991e+11</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean         stdev      corr         covar      beta\n",
       "mean    6820.889570   2664.480345  0.481387  1.919647e+10  0.000119\n",
       "std    13492.039026   4048.940496  0.365678  4.245542e+10  0.000263\n",
       "min      122.235276     67.364259 -1.000000 -2.127961e+11 -0.001319\n",
       "25%      752.050987    477.289633  0.230151  1.281612e+09  0.000008\n",
       "50%     2396.810028   1250.690582  0.513409  5.983286e+09  0.000037\n",
       "75%     8446.905268   3177.137782  0.802041  2.531106e+10  0.000157\n",
       "max   109458.201106  44378.120027  1.000000  4.158991e+11  0.002579"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/14 22:25:03 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 305719 ms exceeds timeout 120000 ms\n",
      "22/09/14 22:25:03 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "mean_sd_corr_nperiods_fortnight.describe().drop(['merchant_abn', 'n_periods'], axis=1)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
