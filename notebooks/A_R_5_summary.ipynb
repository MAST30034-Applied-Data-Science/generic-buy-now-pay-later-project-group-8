{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buy Now, Pay Later Project - Group 8\n",
    "# Applied Data Science (MAST30034)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Problem overview  <br><br>\n",
    "    1.1&nbsp;&nbsp; Overview of our insight in producing the solution <br><br>\n",
    "2. Data  <br><br>\n",
    "    2.1&nbsp;&nbsp; Synthetically generated data provided by the teaching team  \n",
    "    2.2&nbsp;&nbsp; External dataset (obtain from the Australian Bureau of Statistics (ABS)) <br><br>\n",
    "3. Understanding data and cleaning  <br><br>\n",
    "    3.1&nbsp;&nbsp; General overview on synthesis datasets  \n",
    "    3.2&nbsp;&nbsp; Cleaning the synthetic datasets    \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.2.3&nbsp;&nbsp;&nbsp;&nbsp; Resolving the missing merchants' details  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.3.1&nbsp;&nbsp;&nbsp;&nbsp; Classification (not successful)    \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.3.2&nbsp;&nbsp;&nbsp;&nbsp; Clustering and imputation  \n",
    "    3.3&nbsp;&nbsp; Dealing with fraudulent data  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.3.1&nbsp;&nbsp;&nbsp;&nbsp; Implementing a merchant fraud detection model (not successful)  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.3.2&nbsp;&nbsp;&nbsp;&nbsp; Implementing a consumer fraud detection model  \n",
    "    3.4&nbsp;&nbsp; General overview on external datasets  \n",
    "    3.5&nbsp;&nbsp; Cleaning the external datasets  <br><br>\n",
    "4. Determining segments of merchant<br><br>\n",
    "5. Ranking model assumptions (usage of variables and its intuition)<br><br>\n",
    "6. Result of model<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/05 21:56:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# import the necessary library and run spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"preprocessing of taxi data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem overview \n",
    "\n",
    "A generic Buy Now, Pay Later (BNPL) firm has begun offering \n",
    "a new “Pay in 5 Installments” feature. Merchants are looking to form a partnership as it may boost their customer base, the BNPL firm in return gets a small percentage of revenue to cover their operating cost. However, the BNPL firm can only onboard at most 100 < X number of merchants every year due to limited resources. Hence, we will design a ranking system for the merchants to assist the firm in selecting merchants that they should accept.\n",
    "\n",
    "### 1.1 Overview of our insight in producing the solution\n",
    "\n",
    "As a **firm that has just begun their business**, we believe that their business goals is to **earn profit while \n",
    "maintaining a long-term establishment of their business**. Hence, when selecting merchants we believe that the monetary worth of cashflows which a merchant can bring for the BNPL firm is not the sole criterion for this new firm picking business partners.\n",
    "\n",
    "High returns may come with high risks, merchants could be making a 100,000 in a month and is out of business for the rest of the year, this could possibly impact the cash flow in the BNPL firm. As a new establish firm may not have a stable cash flow, this may hinder the objective of staying in business for a long-term and create financial risk, hence, we aim to select merchants that provide a **stable return**.\n",
    "\n",
    "Also, as a newly establish firm, we believe that the firm **may not have a large and strong consumer base that uses their services**. Hence, merchants with a young customer demographic and other features (explained in Ranking model assumption) are also consider when creating a ranking system for the merchant.\n",
    "\n",
    "Thus, our solution is based on our domain knowledge in Finance and Economics which give intutions of what goals the firm may have, and hopes to **maintain a stable profit to allow the firm to stay in operation but also help expand the firm for better revenues in the future**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 2.1 Synthetically generated data provided by the teaching team\n",
    "These are data related to the BNPL firm.\n",
    "- Merchant data (merchants that are to be consider for selections)\n",
    "    - Contains information about merchants including merchant ABN, merchant name, take rate, product description, and revenue level.\n",
    "    - Each data entry is an unique merchant as define by their unique merchant ABN. <br><br> \n",
    "- Consumer data (consumers that may have a purchase in one of the merchants)\n",
    "    - Contains information about consumers including consumer_id, name, address\tstate, postcode, and gender.\n",
    "    - Each data entry is an unique consumer as define by their unique consumer ID. <br><br> \n",
    "- Transaction data (raw transactions of merchants)\n",
    "    - Contains information about transactions of merchant including user_id, merchant_abn, dollar_value, order_id,\tand order_datetime. \n",
    "    - Each data entry is an unique order. <br><br> \n",
    "- Consumer details (A conversion table to allow Transaction to join with consumers)\n",
    "    - Two columns, user_id and consumer_id. <br><br> \n",
    "- Merchant fraud probability data\n",
    "    - Contains merchant_abn, order_datetime, fraud probability\n",
    "    - Each data entry represent the chance the entire batch of transaction done with that merchant on that day could be considered fraudulent. <br><br> \n",
    "- Consumer fraud probability data\n",
    "    - Contains user_id, order_datetime, fraud probability\n",
    "    - Each data entry represent the chance the entire batch of transaction done by that consumer on that day could be considered fraudulent.\n",
    "\n",
    "* ** As the third set of transactions data were labelled to end at August 20th 2022, but actual transactions dated up to October 2022, it was decided to remove all transactions after August 20th 2022 to keep in line with the spec. This is just like treating data after August 20th 2022 as input errors ** *\n",
    "\n",
    "### 2.2 External dataset (obtain from the Australian Bureau of Statistics (ABS))\n",
    "These are external datasets that provide demographic statistics about a post code in Australia, as the actual real-life component of the provided datasets are the postcodes of the consumers.\n",
    "- 2016 Age data \n",
    "    - Contains the reported count of age 0 to 115, and the total reported population count.\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "- 2016 Education data\n",
    "    - Contains the reported count of students, part-time, full-time, TAFE, total students\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "- Income data\n",
    "    - Contains the weekly total personal income counts under income categories ranging from $1 to $3000 or more, incrementing by $150.\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding data and cleaning\n",
    "### 3.1 General overview on synthesis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reading in the data\n",
    "transact_data1 = spark.read.parquet(\"../data/tables/transactions_20210228_20210827_snapshot/\")\n",
    "transact_data2 = spark.read.parquet(\"../data/tables/transactions_20210828_20220227_snapshot/\")\n",
    "transact_data3 = spark.read.parquet(\"../data/tables/transactions_20220228_20220828_snapshot/\")\n",
    "transactions_sdf = transact_data1.union(transact_data2)\n",
    "transactions_sdf = transactions_sdf.union(transact_data3)\n",
    "merchant_sdf = spark.read.parquet(\"../data/tables/tbl_merchants.parquet\")\n",
    "consumer_sdf = spark.read.option(\"header\",True) \\\n",
    "                         .option(\"inferSchema\",True) \\\n",
    "                         .options(delimiter='|') \\\n",
    "                         .csv(\"../data/tables/tbl_consumer.csv\")\n",
    "consumer_fraud = spark.read.option(\"header\",True).csv('../data/tables/consumer_fraud_probability.csv', )\n",
    "merchant_fraud = spark.read.option(\"header\",True).csv('../data/tables/merchant_fraud_probability.csv', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at the dataset sizes and what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14195505 entries of the Transactions dataset\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|  18478| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 4026 entries of the Merchants dataset\n",
      "+-------------+--------------------+------------+\n",
      "|         name|                tags|merchant_abn|\n",
      "+-------------+--------------------+------------+\n",
      "|Felis Limited|((furniture, home...| 10023283211|\n",
      "+-------------+--------------------+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 499999 entries of the Consumers dataset\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|            name|             address|state|postcode|gender|consumer_id|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|Yolanda Williams|413 Haney Gardens...|   WA|    6935|Female|    1195503|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the first row of the datasets\n",
    "print(f'There are {transactions_sdf.count()} entries of the Transactions dataset')\n",
    "print(transactions_sdf.show(1))\n",
    "print(f'There are {merchant_sdf.count()} entries of the Merchants dataset')\n",
    "print(merchant_sdf.show(1))\n",
    "print(f'There are {consumer_sdf.count()} entries of the Consumers dataset')\n",
    "print(consumer_sdf.show(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34864 entries of the Consumer fraud probability dataset\n",
      "+-------+--------------+-----------------+\n",
      "|user_id|order_datetime|fraud_probability|\n",
      "+-------+--------------+-----------------+\n",
      "|   6228|    2021-12-19| 97.6298077657765|\n",
      "+-------+--------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 114 entries of the Merchant fraud probability dataset\n",
      "+------------+--------------+------------------+\n",
      "|merchant_abn|order_datetime| fraud_probability|\n",
      "+------------+--------------+------------------+\n",
      "| 19492220327|    2021-11-28|44.403658647495355|\n",
      "+------------+--------------+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the first row of the datasets\n",
    "print(f'There are {consumer_fraud.count()} entries of the Consumer fraud probability dataset')\n",
    "print(consumer_fraud.show(1))\n",
    "print(f'There are {merchant_fraud.count()} entries of the Merchant fraud probability dataset')\n",
    "print(merchant_fraud.show(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cleaning the synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merchant dataset\n",
    "From the presented row above of the merchant dataset, it is found that the tags column contains information about product description, revenue level, and take rate. Such information is extracted and treated as separate columns, for better visual and easier code handling for later analysis and feature engineering.  \n",
    "\n",
    "#### Transaction dataset\n",
    "The transactions are consider to be within the time range of 2021-02-28 to 2022-08-28. However, it is found that the dataset contains transactions past the time range and such transactions are removed.\n",
    "\n",
    "#### Joining the merchant, consumer, and transaction dataset to check if there are any missing information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "|user_id|merchant_abn|dollar_value|order_id|merchant_name|prod_desc|revenue_level|take_rate|consumer_name|address|state|postcode|gender|consumer_id|\n",
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "|      0|           0|           0|       0|       149228|   149228|       149228|   149228|            0|      0|    0|       0|     0|          0|\n",
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing if there are any missing values in the columns\n",
    "transaction_20210228_20210827_missings_sdf = spark.read.parquet(\"../data/curated/transactions_20210228_20210827_all_details_missing_counts\")\n",
    "transaction_20210228_20210827_missings_sdf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is found that there are merchants with no information about them, however, we decided not to discard such merchants as they have transaction and customer records that may be worth selecting for the firm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Resolving the missing merchants' details\n",
    "We first decided to create a classification model that is able to help classify the missing merchant details, however, the model's accuracy was too low. Hence, we resolved with clustering the unknown merchants into the known merchant clusters and performed a mean imputation for take rate as it is the variable we require for further calculations and investigation for the ranking system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3.1 Classification (not successful)    \n",
    "\n",
    "**Objective**: Predict product description, revenue level and take rate of the missing merchants "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the markdown cell below to see the classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification pipeline**:  \n",
    " 0. Preliminary Data Analysis  \n",
    " 1. Data Engineering\n",
    "  * Mostly done in ETL\n",
    "    * Encode revenue level into integer value, e.g. 1, 2, 3, 4, 5\n",
    "    * Clean the prod_desc (has been updated in ETL)\n",
    "  * Need one curated dataset for modeling product description and one dataset for modeling revenue level and take rate\n",
    " 2. Feature Engineering\n",
    "  * Aggregate data to produce more useful features for modeling revenue level and take rate\n",
    "  * Recommended features for prod_desc: dollar value, user id and order datetime\n",
    "  * Recommended features for revenue level and take rate: monthly average revenue,  monthly average number of orders, monthly average number of distinct customers, average revenue per order, median revenue, variance of dollar amount\n",
    " 3. Data Modeling\n",
    "  * Choice of classification model: XGBClassifier, RandomForest, Naive Bayes(Last resort)\n",
    "  * Choice of regression model: Linear regression, XGBregressor\n",
    "  * Fitting and Tuning model to achieve optimal performance \n",
    " 4. Model Validation\n",
    " * Metrics:\n",
    "    * Categorical(prod_desc and revenue_level): \n",
    "      * Accuracy\n",
    "      * f1 score\n",
    "    * Continuous(take_rate):\n",
    "      * RMSE\n",
    " * Visualization:\n",
    "    * Categorical:\n",
    "      * learning curve\n",
    "      * ROC curve\n",
    "      * confusion matrix \n",
    "    * Continuous:\n",
    "      * RMSE vs. fitted value\n",
    " 5. Model deployment\n",
    "   * Use the prediction to impute missing information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the models have poor performance in terms of accuracy/RMSE, it is not feasible to deploy them in an imputation process. From our perspectives, tuning the model will be ultimately a waste of time because it will only refine our model instead of improving it significantly. <u>Therefore, we resolve into clustering.</u> We believe that the merchant are not fully represented in regards to take rate, product description, and revenue level, under our engineered features.\n",
    "\n",
    "To see the classification models and their performance click [classify_missing_merchants](./A_Y_H_classify_missing_merchants.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3.2 Clustering and imputation \n",
    "**Objective**: Perform clustering on the merchants to obtain 3 to 5 clusters, which can be used for market segmentation and take rate imputation\n",
    "\n",
    "We clustered the merchants based on their consumer base, average monthly order, average monthly revenue. Given we only have transaction and consumer data on the unknown merchants, we believe that the 3 features we created can help group similar merchants based on the business sizes evaluated by the features. We utilized **K-means, MeanShift, DBSCAN, Gausian Mixutre Model**, and evaluated their performance under **Silhouette Coefficient, Calinski-Harabasz Index, and Davies-Bouldin Index**. We found that the Gausian Mixture model performed the best. Below presents the clusters for a quick visualization,  <br><br>\n",
    "<img src=\"GMMclusters.png\" width=\"1000\" class=\"center\"> <br><br>\n",
    "\n",
    "After creating the clusters, **we fit the unknown merchants into the clusters and impute the take rates of such unknown merchants by the mean of the take rates of their respective clusters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dealing with Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BNPL buisiness model can be understood as: the merchants gain extra revenue from impulse spending because of the low upfront cost, and is guarenteed the full amount of the purchase (less the take rate) is received immediately, for the cost of the take rate; the BNPL firm receives the take rate, with the cost being operational cost, lost interest rate on later instalments, and risk of consumers not paying back (default risk).\n",
    "\n",
    "Two datasets were provided by the teaching staff, the first consisting of a small sample of merchants-day and the second consisting of a small sample of consumer-day, labelled with probability of fraud. It was assumed that if i.e. a consumer-day was 'fraudulant', then all its transacitons on the day should be dsicarded. \n",
    "\n",
    "Although not every transaction may have been fradulant, the cost of a fraudulant transaction that is bought upon the BNPL company should be greater than the transaction sum itself (i.e. it would have to cough up (1-take rate) * transaction because under the business model it bears the transaction risk in return for the take rate); hence, if a consumer-day was considered fradulant, then all transactions on that day would be thrown out (i.e. could have earned money on other transactions - but those would be used to balance out the cost brought by the fraudulant transactions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1 Dealing with consumer fraud\n",
    "\n",
    "We treated this problem as a supervised learning problem, with labels being predicted fraud probability. We chose to use the continuous predicting model of random forest regressor.\n",
    "\n",
    "We treated each consumer-day (i.e. each row in the fraud dataset) as an instance, and engineered variables such as the average transaction amount on that day by that consumer; the sd of transaction amounts on the day by that customer; the number of transactions they had; and number of distinct stores they shopped at. All these were derived by joining fraud dataset with transaction dataset and then aggregating.\n",
    "\n",
    "Four other variables were also engineered: i.e. number of distinct stores they shopped at on day of being labelled / average number of distinct stores they shopped at in the past days when they made at least one transaction. The same idea was implemented for the other three variables. The latter 4 variables are expected to give a ratio that standardises each consumer-day by the consumer's historic behaviour, to make different consumers more comparable. They are denoted by appending the word 'ratio' behind the name.\n",
    "\n",
    "Ultimately, 'transaction amount per order ratio', 'transaction amount per order', 'sd of transaction amounts on the day', 'sd of transaction amounts on the day ratio' were chosen as variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>max_features</th>\n",
       "      <th>ccp_alpha</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.91441</td>\n",
       "      <td>0.798436</td>\n",
       "      <td>0.798915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  n_estimators  max_depth  max_samples  max_features  \\\n",
       "757           0           150         18          0.5          0.75   \n",
       "\n",
       "     ccp_alpha  training_accuracy  validation_accuracy  testing_accuracy  \n",
       "757      0.001            0.91441             0.798436          0.798915  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_tuning = pd.read_csv('../data/tuning/RFR_brute.csv')\n",
    "rfr_tuning.sort_values(['validation_accuracy'], ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, the best combination of hyperparameters gave validation R^2 and testing R^2 of 0.798, which are very good results.\n",
    "\n",
    "However, upon inspecting the predicted values (on the whole dataset), it was found that a lot of the consumer-day had extremely low predicted fraud probability (around 9%), so the predicted results were only good for ranking as opposed to actual intuition. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fraud = pd.read_csv('../data/curated/fraud/final_fraud_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.394051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.920289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.411906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.362188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud rate\n",
       "mean    9.394051\n",
       "std     0.920289\n",
       "min     9.287148\n",
       "25%     9.287148\n",
       "50%     9.287148\n",
       "75%     9.411906\n",
       "max    85.362188"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_fraud[['fraud rate']].describe()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, it was decided to only remove about 0.1% of the transactions and hence the threshold for fradulant data was set at 20% predicted fraud. The 0.1% came about because we believed anything less would be so insignificant that this fraud detection task would not be worth doing; while any higher would mean the BNPL firm loses money (because the take rate margin are in general so slim)\n",
    "\n",
    "Although this outcome is not as good as i.e. there was a more spread out distribution and the cutoff rate could be higher, in the end the threshold was always going to be manually determined, and practically does not make much of a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2 Dealing with merchant fraud\n",
    "\n",
    "Although the exact process could be repeated for the merchant fraud, we deemed it unviable and unnecessary because\n",
    "\n",
    "1. there were only 114 rows of data with labels - not nearly enough to train a model given our method of treating each merchant-day as an instance. Inaccurate models risk throwing out too many transactions that were in reality not fraud\n",
    "\n",
    "2. we already have a sufficient model dealing with fraud for consumers that would be run over all data, so a merchatn fraud model would be complimentary rather than a necessity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3 Final removal\n",
    "\n",
    "Just running the consumer fraud model over the entire dataset, approximately 16000 of the 14 million transactions were removed. \n",
    "\n",
    "14179422 transactions were left after the removal of fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 General overview of the external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "income_sdf = spark.read.option(\"header\",True).csv('../data/curated/income.csv')\n",
    "age_sdf = spark.read.option(\"header\",True).csv('../data/curated/2016_age.csv')\n",
    "education_sdf = spark.read.option(\"header\",True).csv('../data/curated/2016_education.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2653 entries of the income dataset\n",
      "root\n",
      " |-- INCP Total Personal Income (weekly): string (nullable = true)\n",
      " |-- Negative income: string (nullable = true)\n",
      " |-- Nil income: string (nullable = true)\n",
      " |-- $1-$149 ($1-$7,799): string (nullable = true)\n",
      " |-- $150-$299 ($7,800-$15,599): string (nullable = true)\n",
      " |-- $300-$399 ($15,600-$20,799): string (nullable = true)\n",
      " |-- $400-$499 ($20,800-$25,999): string (nullable = true)\n",
      " |-- $500-$649 ($26,000-$33,799): string (nullable = true)\n",
      " |-- $650-$799 ($33,800-$41,599): string (nullable = true)\n",
      " |-- $800-$999 ($41,600-$51,999): string (nullable = true)\n",
      " |-- $1,000-$1,249 ($52,000-$64,999): string (nullable = true)\n",
      " |-- $1,250-$1,499 ($65,000-$77,999): string (nullable = true)\n",
      " |-- $1,500-$1,749 ($78,000-$90,999): string (nullable = true)\n",
      " |-- $1,750-$1,999 ($91,000-$103,999): string (nullable = true)\n",
      " |-- $2,000-$2,999 ($104,000-$155,999): string (nullable = true)\n",
      " |-- $3,000 or more ($156,000 or more): string (nullable = true)\n",
      " |-- Not stated: string (nullable = true)\n",
      " |-- Not applicable: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the income dataset\n",
    "print(f'There are {income_sdf.count()} entries of the income dataset')\n",
    "print(income_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2653 entries of the age dataset\n",
      "root\n",
      " |-- AGEP Age: string (nullable = true)\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- 2: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 4: string (nullable = true)\n",
      " |-- 5: string (nullable = true)\n",
      " |-- 6: string (nullable = true)\n",
      " |-- 7: string (nullable = true)\n",
      " |-- 8: string (nullable = true)\n",
      " |-- 9: string (nullable = true)\n",
      " |-- 10: string (nullable = true)\n",
      " |-- 11: string (nullable = true)\n",
      " |-- 12: string (nullable = true)\n",
      " |-- 13: string (nullable = true)\n",
      " |-- 14: string (nullable = true)\n",
      " |-- 15: string (nullable = true)\n",
      " |-- 16: string (nullable = true)\n",
      " |-- 17: string (nullable = true)\n",
      " |-- 18: string (nullable = true)\n",
      " |-- 19: string (nullable = true)\n",
      " |-- 20: string (nullable = true)\n",
      " |-- 21: string (nullable = true)\n",
      " |-- 22: string (nullable = true)\n",
      " |-- 23: string (nullable = true)\n",
      " |-- 24: string (nullable = true)\n",
      " |-- 25: string (nullable = true)\n",
      " |-- 26: string (nullable = true)\n",
      " |-- 27: string (nullable = true)\n",
      " |-- 28: string (nullable = true)\n",
      " |-- 29: string (nullable = true)\n",
      " |-- 30: string (nullable = true)\n",
      " |-- 31: string (nullable = true)\n",
      " |-- 32: string (nullable = true)\n",
      " |-- 33: string (nullable = true)\n",
      " |-- 34: string (nullable = true)\n",
      " |-- 35: string (nullable = true)\n",
      " |-- 36: string (nullable = true)\n",
      " |-- 37: string (nullable = true)\n",
      " |-- 38: string (nullable = true)\n",
      " |-- 39: string (nullable = true)\n",
      " |-- 40: string (nullable = true)\n",
      " |-- 41: string (nullable = true)\n",
      " |-- 42: string (nullable = true)\n",
      " |-- 43: string (nullable = true)\n",
      " |-- 44: string (nullable = true)\n",
      " |-- 45: string (nullable = true)\n",
      " |-- 46: string (nullable = true)\n",
      " |-- 47: string (nullable = true)\n",
      " |-- 48: string (nullable = true)\n",
      " |-- 49: string (nullable = true)\n",
      " |-- 50: string (nullable = true)\n",
      " |-- 51: string (nullable = true)\n",
      " |-- 52: string (nullable = true)\n",
      " |-- 53: string (nullable = true)\n",
      " |-- 54: string (nullable = true)\n",
      " |-- 55: string (nullable = true)\n",
      " |-- 56: string (nullable = true)\n",
      " |-- 57: string (nullable = true)\n",
      " |-- 58: string (nullable = true)\n",
      " |-- 59: string (nullable = true)\n",
      " |-- 60: string (nullable = true)\n",
      " |-- 61: string (nullable = true)\n",
      " |-- 62: string (nullable = true)\n",
      " |-- 63: string (nullable = true)\n",
      " |-- 64: string (nullable = true)\n",
      " |-- 65: string (nullable = true)\n",
      " |-- 66: string (nullable = true)\n",
      " |-- 67: string (nullable = true)\n",
      " |-- 68: string (nullable = true)\n",
      " |-- 69: string (nullable = true)\n",
      " |-- 70: string (nullable = true)\n",
      " |-- 71: string (nullable = true)\n",
      " |-- 72: string (nullable = true)\n",
      " |-- 73: string (nullable = true)\n",
      " |-- 74: string (nullable = true)\n",
      " |-- 75: string (nullable = true)\n",
      " |-- 76: string (nullable = true)\n",
      " |-- 77: string (nullable = true)\n",
      " |-- 78: string (nullable = true)\n",
      " |-- 79: string (nullable = true)\n",
      " |-- 80: string (nullable = true)\n",
      " |-- 81: string (nullable = true)\n",
      " |-- 82: string (nullable = true)\n",
      " |-- 83: string (nullable = true)\n",
      " |-- 84: string (nullable = true)\n",
      " |-- 85: string (nullable = true)\n",
      " |-- 86: string (nullable = true)\n",
      " |-- 87: string (nullable = true)\n",
      " |-- 88: string (nullable = true)\n",
      " |-- 89: string (nullable = true)\n",
      " |-- 90: string (nullable = true)\n",
      " |-- 91: string (nullable = true)\n",
      " |-- 92: string (nullable = true)\n",
      " |-- 93: string (nullable = true)\n",
      " |-- 94: string (nullable = true)\n",
      " |-- 95: string (nullable = true)\n",
      " |-- 96: string (nullable = true)\n",
      " |-- 97: string (nullable = true)\n",
      " |-- 98: string (nullable = true)\n",
      " |-- 99: string (nullable = true)\n",
      " |-- 100: string (nullable = true)\n",
      " |-- 101: string (nullable = true)\n",
      " |-- 102: string (nullable = true)\n",
      " |-- 103: string (nullable = true)\n",
      " |-- 104: string (nullable = true)\n",
      " |-- 105: string (nullable = true)\n",
      " |-- 106: string (nullable = true)\n",
      " |-- 107: string (nullable = true)\n",
      " |-- 108: string (nullable = true)\n",
      " |-- 109: string (nullable = true)\n",
      " |-- 110: string (nullable = true)\n",
      " |-- 111: string (nullable = true)\n",
      " |-- 112: string (nullable = true)\n",
      " |-- 113: string (nullable = true)\n",
      " |-- 114: string (nullable = true)\n",
      " |-- 115: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the age dataset\n",
    "print(f'There are {age_sdf.count()} entries of the age dataset')\n",
    "print(age_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2668 entries of the education dataset\n",
      "root\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Part-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Part-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time/Part-time student status not stated: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Part-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Part-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time/Part-time student status not stated: string (nullable = true)\n",
      " |-- Other: Full-time student: string (nullable = true)\n",
      " |-- Other: Part-time student: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the education dataset\n",
    "print(f'There are {education_sdf.count()} entries of the education dataset')\n",
    "print(education_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Cleaning the external datasets\n",
    "\n",
    "We check for any missing values and string formatting issues that are presented in the data sets and found that are none, aggregation and feature engineering was done later in the calculations of the ranking persona feature variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background and intuition: \n",
    "\n",
    "The goal of our ranking model was to return a portfolio of 100 companies which maximise the Sharpe Ratio. The Sharpe Ratio is a finance concept which for our problem equals to E( (revenue * take rate) of the whole portfolio ) / sd( (revenue * take rate) of the whole portfolio ). The purpose of using this metric is because as a company, having high incoming cashflow is of course predominantly good, but if high cashflows come with high variance, this could put the buisiness at financial risk, which brings along implicit bankruptcy costs etc; by using the Sharpe Ratio to evaluate the portfolio of 100 companies, we can guarentee that we have maximised the amount of incoming cashflow from merchant revenue * take rate for all the risk (standard deviation) we have chosen. \n",
    "\n",
    "Our ranking model consists a heuristic function, which is a linear function that returns the score for each merchant based on several variables. The top 100 ranking merchants would then be selected to be the final 100 merchants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables used in the linear heuristc function are: \n",
    "1. Historic mean (revenue * take rate) of the firm\n",
    "2. Historic sd of (revenue * take rate) of the firm/Historic mean (revenue * take rate) of the firm\n",
    "3. Historic corr of (revenue * take rate) of the firm and (revenue & take rate) of all companies in the market\n",
    "4. Loyalty rate  \n",
    "    The loyalty variable is a variable design to measure a merchants consumer base, we wanted merchants with loyal customers that are staying with them, thus, when we select such merchant for partnerships, it is highly possible such consumers can be converted in to our customers.\n",
    "    By providing a after pay method, it is likely they would try to use it to purchase more frequently at their \"favorite\" store, thus, introduced to our firm's service and even use it to purchase in other merchants.\n",
    "5. Persona score \n",
    "    The persona score is a score given to a merchant based on its consumers demographic statistics.\n",
    "    Compose of 4 components:\n",
    "    - Age \n",
    "        Young is better, as they have the ability to communicate through social media and promote the firm, and are more willing to convert or accept the financial payment methods.\n",
    "    - Education\n",
    "        we wanted students because by reference (), many BNPL users are students\n",
    "    - Income\n",
    "        we wanted high income consumers, so they are able to repay or repay stably the buy now pay later installments, in the future\n",
    "    - Total population\n",
    "        wanted consumers coming from areas with high population.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Growth rate was attempted as a variable, but was found to be not useful\n",
    "\n",
    "*To calculate the sd of firms, company's transactions were grouped by fortnight*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of tuning coefficients for variables in linear function:\n",
    "0. Split our data into 23 fortnights for training and 13 fortnights for validation\n",
    "1. Iterate over different combinations of coefficients for each variable for the linear heuristic function\n",
    "2. Use this linear function to calculate the score for each merchant, and rank it\n",
    "3. Take the top 100 scoring merchants and form a portfolio, and then calculate its Sharpe Ratio in the validation set\n",
    "4. The set of combination of coefficients with the highest validation sharpe ratio will be the final coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions and alterations of financial theories\n",
    "\n",
    "- The 'market' which the correlation compares to here is not the most efficient portfolio that real stock market finance analysts use - they calculate correlation of a share to the 'market portfolio', but here because we do not have a 'risk free rate', nor have resources to calculate the efficient portfolio, thus we just use the portfolio of all companies together as our 'market'.\n",
    "\n",
    "- As stated above, we do not have a risk free rate; also we do not need to put in initial investment amount (it is like getting to invest in 100 stocks for free), so instead of using E(return rate) and sd(return rate) etc which what finance analysts do, we use E(revenue * take rate) and sd(revenue * take rate)\n",
    "\n",
    "- Also, in real finance, a portfolio would consist of different weighting of stocks (i.e. 1/2 money in stock A, 1/3 money in stock B and 1/6 money in stock C), and the sum of weights must add up to 1. However, here, our portfolio's 'weights' add up to 100, and each merchant's weight can only ever be 1. (alternatively can think of as weight = 1/100, but because we are dealoign with E( return rate ) it is best to use w=1, sum(w_i) = 100)\n",
    "\n",
    "- in training our model, we also assume that the business transaction behaviour during the 'train' period and 'test' period are similar when a portfolio of multiple merchants are considered, and that the behaviour of the whole period is similar to the train and test \n",
    "\n",
    "- the act of using the same data (split into two segments) to tune up the model and then using the overall data to get a final result inherently causes overfit; but this risk/disadvantage is smaller than i.e. using a smaller section of unseen data to do final prediction. This is because the data provided only spans 18 months, which is 39 fortnights, and if splitting into three parts will likely hurt the model more than the overfit component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Result of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final tuned coefficients (after several rounds of tuning and refinement) to the heuristic linear function was:\n",
    "\n",
    "{60, -230000000, 105750000000, -6000000000, 602500000000}\n",
    "\n",
    "So the final equation is:\n",
    "\n",
    "score of company = 60 * historic mean - 230000000 * standardised historic sd + 105750000000 * historic corr - 6000000000 loyalty + 602500000000 * persona score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation:\n",
    "\n",
    "We must first note that the scale of each of these variables are not the same (i.e. the average value of historic mean between all companies in the training set is 90000, whilst correlation can only exist within [-1, 1])\n",
    "\n",
    "A primary interpretation and recommendation can be derived based on the sign of the coefficients.\n",
    "\n",
    "A merchant that contributes to creating a high sharpe ratio portfolio in the next period would be rewarded (in points) for high (historic mean revenue * take rate), low standardized historic sd, higher historical correlation, lower loyalty and higher persona score.\n",
    "\n",
    "The signs of the first two variables' coefficients are not surprising, given that sharpe ratios are higher when mean are higher and standard deviation is lower. The signs on correlation's coefficient is more surprising - we expected it to be negative given in probability theory, having lower/negative correlation helps lower the standard deviation of the sum of random variables (in this case random variables being revenue of each merchant). Also, using intuition, we would perhaps hope that the firms would be uncorrelated with the market so that the firm's incomes are stable and are less affected by external factors. \n",
    "\n",
    "One possible explanation is that the model has not put much emphasis on the historic mean variable (as seen by its small correlation coefficient compared to other variables - even after considering that its typical values are much larger than other variables), and so the correlation with the 'market' is in fact capturing information of high (revenue * take rate) which is also important for a high sharpe ratio. In short, it may be that in driving for high sharpe ratio, the emphasis has been placed on lower standard deviation, and instead the high numerator (mean revenue * take rate) part is captured in the correlation.\n",
    "\n",
    "An explanation for the negative loyalty rate is that BNPL is more reliant on firms that attract new customers rather than retaining old customers. This is because, a loyal customer may be beneficial to the merchant as they generate consistent revenue for them, however, as a BNPL firm if such customer rejects our service after we selected the merchant, such merchant will not generate as much revenue as we hoped. Hence, the model favours merchant that has more \"un-loyal\" customers and hence could reduce our advertisement cost while reaching out to more customers.\n",
    "\n",
    "The persona variable makes perfect sense because it effectively measures how well the customer demographic fits the demographic that is favoured by BNPL business models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know that each variable was actualy useful?\n",
    "\n",
    "Because this is an unsupervised problem, we cannot do things such as AIC stepwise or feature selection F test to ensure the usefulness of each variable\n",
    "\n",
    "In training we tried ran the training process (combinations of each variable taking on values {0.0001, 0.01, 1, 100, 10000, -0.0001, -0.01, -1, -100, -10000} on just the first variable (historic mean revenue * take rate), then two variables (+ historic sd of revenue * take rate), then three variables (+ historic corr), then all 5 variables together, and each time we added more variables, we got to a higher validation sharpe ratios, meaning that the extra variables helped us distinguish companies that made the validation final portfolio better performing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 100 companies are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/curated/final_model/final_top100.csv')\n",
    "persona_score = pd.read_csv('../data/curated/persona_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57564805948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31400548982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49465266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62789659343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99801770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10881038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89640578182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>37459245212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>49514806178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48549026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20562405782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>91720867026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50866797623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30122382323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68559320474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>61447419161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>88547577701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>41001282470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>94472466107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21359184622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49322182190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90543168331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>31585975447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>80682333501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62224020443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35556933338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>98671274602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27093785141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80779820715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>54550134954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>34096466752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>80518954462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49212265466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>53877856360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>71961434094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96880556465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>76767266140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>51527394775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>22059270846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>93558142492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>68004106739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>18158387243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>58454491168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>96680767841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15560455575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>33604812025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19618998054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>79633007926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>70501974849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>37379915451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    merchant_abn\n",
       "0    57564805948\n",
       "1    31400548982\n",
       "2    49465266764\n",
       "3    62789659343\n",
       "4    99801770627\n",
       "5    10881038707\n",
       "6    89640578182\n",
       "7    37459245212\n",
       "8    49514806178\n",
       "9    48549026640\n",
       "10   20562405782\n",
       "11   91720867026\n",
       "12   50866797623\n",
       "13   30122382323\n",
       "14   68559320474\n",
       "15   61447419161\n",
       "16   88547577701\n",
       "17   41001282470\n",
       "18   94472466107\n",
       "19   21359184622\n",
       "20   49322182190\n",
       "21   90543168331\n",
       "22   31585975447\n",
       "23   80682333501\n",
       "24   62224020443\n",
       "25   35556933338\n",
       "26   98671274602\n",
       "27   27093785141\n",
       "28   80779820715\n",
       "29   54550134954\n",
       "30   34096466752\n",
       "31   80518954462\n",
       "32   49212265466\n",
       "33   53877856360\n",
       "34   71961434094\n",
       "35   96880556465\n",
       "36   76767266140\n",
       "37   51527394775\n",
       "38   22059270846\n",
       "39   93558142492\n",
       "40   68004106739\n",
       "41   18158387243\n",
       "42   58454491168\n",
       "43   96680767841\n",
       "44   15560455575\n",
       "45   33604812025\n",
       "46   19618998054\n",
       "47   79633007926\n",
       "48   70501974849\n",
       "49   37379915451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>89618228232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>23338656015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>56946407125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>99976658299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>73972053940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>52959528548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>41974958954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>40555823280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>47086412084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>52065114842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>46298404088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>81219314324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>75944642726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>81761494572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>63465140133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>29023134283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>22033359776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>17488304283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>35909341340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>41944909975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>36196225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>67400260923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>50315283629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>29566626791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>99776743787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>98973094975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>34179569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>33068332703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>38090089066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>11237511112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>32560075533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>30214222203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>76626119831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83690644458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>80109801322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>67794222692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10648956813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>71350572766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>81410315303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>67609108741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>51279178333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>96161808980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>48534649627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>52160665475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>13514558491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>89502033586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>49505931725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>91873181182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>90087872851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>75034515922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    merchant_abn\n",
       "50   89618228232\n",
       "51   23338656015\n",
       "52   56946407125\n",
       "53   99976658299\n",
       "54   73972053940\n",
       "55   52959528548\n",
       "56   41974958954\n",
       "57   40555823280\n",
       "58   47086412084\n",
       "59   52065114842\n",
       "60   46298404088\n",
       "61   81219314324\n",
       "62   75944642726\n",
       "63   81761494572\n",
       "64   63465140133\n",
       "65   29023134283\n",
       "66   22033359776\n",
       "67   17488304283\n",
       "68   35909341340\n",
       "69   41944909975\n",
       "70   36196225600\n",
       "71   67400260923\n",
       "72   50315283629\n",
       "73   29566626791\n",
       "74   99776743787\n",
       "75   98973094975\n",
       "76   34179569263\n",
       "77   33068332703\n",
       "78   38090089066\n",
       "79   11237511112\n",
       "80   32560075533\n",
       "81   30214222203\n",
       "82   76626119831\n",
       "83   83690644458\n",
       "84   80109801322\n",
       "85   67794222692\n",
       "86   10648956813\n",
       "87   71350572766\n",
       "88   81410315303\n",
       "89   67609108741\n",
       "90   51279178333\n",
       "91   96161808980\n",
       "92   48534649627\n",
       "93   52160665475\n",
       "94   13514558491\n",
       "95   89502033586\n",
       "96   49505931725\n",
       "97   91873181182\n",
       "98   90087872851\n",
       "99   75034515922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[['merchant_abn']].head(50))\n",
    "display(data[['merchant_abn']].tail(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 merchants from each self defined cluster are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0: Luxuary goods and art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57564805948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31400548982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49465266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62789659343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99801770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10881038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49514806178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48549026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41001282470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98671274602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   57564805948\n",
       "1   31400548982\n",
       "2   49465266764\n",
       "3   62789659343\n",
       "4   99801770627\n",
       "5   10881038707\n",
       "6   49514806178\n",
       "7   48549026640\n",
       "8   41001282470\n",
       "9   98671274602"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster0.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1: Leisure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89640578182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37459245212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91720867026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50866797623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30122382323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68559320474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61447419161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88547577701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94472466107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21359184622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   89640578182\n",
       "1   37459245212\n",
       "2   91720867026\n",
       "3   50866797623\n",
       "4   30122382323\n",
       "5   68559320474\n",
       "6   61447419161\n",
       "7   88547577701\n",
       "8   94472466107\n",
       "9   21359184622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster1.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 2: Lifestyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20562405782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33604812025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29566626791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74648589246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75342681786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79953723663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67202032418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67330176930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99904689266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91848160033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   20562405782\n",
       "1   33604812025\n",
       "2   29566626791\n",
       "3   74648589246\n",
       "4   75342681786\n",
       "5   79953723663\n",
       "6   67202032418\n",
       "7   67330176930\n",
       "8   99904689266\n",
       "9   91848160033"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster2.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
