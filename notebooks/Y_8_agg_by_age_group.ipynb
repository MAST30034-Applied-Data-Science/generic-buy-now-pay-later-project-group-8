{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation by ages groups for Persona Data Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this notebook, we will aggregate the raw Persona data about age in each postcode to create a tally which contains the counts for each age group and total population over 18 for each postcode in Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from gettext import npgettext\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "from statistics import mean, stdev\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 11:38:50 WARN Utils: Your hostname, Lis-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.13.47.249 instead (on interface en0)\n",
      "22/10/06 11:38:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 11:38:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/06 11:38:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "# setup spark\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"aggregate data for first 3 final model variables\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"../data/curated/2016_age.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('AGEP Age','postcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "### Age bracket is defined by BNPL analysis regarding age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = data.withColumn(\"18-24\", sum(data[col] for col in range(18+1,24+1+1)))\\\n",
    "    .withColumn(\"25-34\", sum(data[col] for col in range(25+1,35+1)))\\\n",
    "    .withColumn(\"35-44\", sum(data[col] for col in range(35+1,45+1)))\\\n",
    "        .withColumn(\"45-54\", sum(data[col] for col in range(45+1,55+1)))\\\n",
    "            .withColumn(\"55-64\", sum(data[col] for col in range(55+1,65+1)))\\\n",
    "                .withColumn(\"65+\", sum(data[col] for col in range(65+1,115+1+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data_agg.select(\"postcode\",\"18-24\",\"25-34\",\"35-44\",\"45-54\",\"55-64\",\"65+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find total popuation (>= 18 Years Old) and keep all postcodes in numeric form only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.withColumn(\"total\", sum(output[col] for col in range(1,7)))\\\n",
    "    .withColumn(\"postcode\",F.regexp_extract('postcode', r'\\d+',0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/06 11:38:55 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "output.toPandas().to_csv('../data/curated/Age_after_agg.csv', index = False)\n",
    "# found that adding the total with ppl<18 cannot made up to the Total in raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigation on the output aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+---+-----+\n",
      "|postcode|18-24|25-34|35-44|45-54|55-64|65+|total|\n",
      "+--------+-----+-----+-----+-----+-----+---+-----+\n",
      "|       0|    0|    0|    0|    0|    0|  0|    0|\n",
      "+--------+-----+-----+-----+-----+-----+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if there is null values \n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "output.select([count(when(isnan(c), c)).alias(c) for c in output.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Found that adding the total with ppl<18 cannot made up to the Total in raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of numbers across rows are different from teh totals in the raw data\n",
    "col_list = [str(i) for i in range(0,116)]\n",
    "df2 = data.withColumn(\n",
    "    'SUM',\n",
    "    sum([F.col(c) for c in col_list])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
