{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona Score Notebook\n",
    "### **Objective**: This notebook aims to define a score for the general profile of customers of a merchant. The higher the score is, the better the merchant.\n",
    "### **Overview**: The persona score is based on **our research and knowledge about the BNPL industry**, and it is comprised of several factors such as median salary and age distributions of that region. Since we only have the geographical location of the customers, we will take the mean of all customers. <u>See the codes for more details</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:30:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/10/04 23:31:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"preprocessing of taxi data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_sdf = spark.read.option(\"header\", True).csv(\"../data/raw/2016_age.csv\")\n",
    "education_sdf = spark.read.option(\"header\", True).csv(\"../data/raw/2016_education.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/10/04 23:31:07 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>sub_total</th><th>18_24</th><th>25_34</th><th>35_44</th><th>45_54</th><th>55_64</th><th>65_plus</th><th>postcode</th></tr>\n",
       "<tr><td>25969.0</td><td>0.2166044129539066</td><td>0.41118256382610036</td><td>0.1598059224459933</td><td>0.08290654241595749</td><td>0.06426893603912356</td><td>0.06523162231891871</td><td>2000</td></tr>\n",
       "<tr><td>1210.0</td><td>0.9347107438016529</td><td>0.045454545454545456</td><td>0.00743801652892562</td><td>0.004958677685950...</td><td>0.00743801652892562</td><td>0.0</td><td>2006</td></tr>\n",
       "<tr><td>8376.0</td><td>0.39983285577841454</td><td>0.3390639923591213</td><td>0.11926934097421203</td><td>0.05742597898758357</td><td>0.04035339063992359</td><td>0.04405444126074499</td><td>2007</td></tr>\n",
       "<tr><td>11191.0</td><td>0.39916003931730853</td><td>0.3594853006880529</td><td>0.10481637029756054</td><td>0.061388615852023945</td><td>0.042623536770619246</td><td>0.032526137074434816</td><td>2008</td></tr>\n",
       "<tr><td>11534.0</td><td>0.1143575515866135</td><td>0.3546904803190567</td><td>0.20469915033813074</td><td>0.11938616264955783</td><td>0.10499393098664817</td><td>0.10187272411999307</td><td>2009</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------+\n",
       "|sub_total|              18_24|               25_34|              35_44|               45_54|               55_64|             65_plus|postcode|\n",
       "+---------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------+\n",
       "|  25969.0| 0.2166044129539066| 0.41118256382610036| 0.1598059224459933| 0.08290654241595749| 0.06426893603912356| 0.06523162231891871|    2000|\n",
       "|   1210.0| 0.9347107438016529|0.045454545454545456|0.00743801652892562|0.004958677685950...| 0.00743801652892562|                 0.0|    2006|\n",
       "|   8376.0|0.39983285577841454|  0.3390639923591213|0.11926934097421203| 0.05742597898758357| 0.04035339063992359| 0.04405444126074499|    2007|\n",
       "|  11191.0|0.39916003931730853|  0.3594853006880529|0.10481637029756054|0.061388615852023945|0.042623536770619246|0.032526137074434816|    2008|\n",
       "|  11534.0| 0.1143575515866135|  0.3546904803190567|0.20469915033813074| 0.11938616264955783| 0.10499393098664817| 0.10187272411999307|    2009|\n",
       "+---------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"sub_total\", \"18_24\", \"25_34\", \n",
    "           \"35_44\", \"45_54\", \"55_64\", \n",
    "           \"65_plus\", \"postcode\"]\n",
    "\n",
    "age_group = columns[:-1]\n",
    "\n",
    "age_sdf = age_sdf.withColumn(columns[0], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(18, 116)])) \\\n",
    "                 .withColumn(columns[1], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(18, 25)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[2], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(25, 35)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[3], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(35, 45)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[4], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(45, 55)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[5], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(55, 65)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[6], reduce(lambda x,y:x+y, [F.col(str(x)) for x in range(65, 116)]) / F.col(columns[0])) \\\n",
    "                 .withColumn(columns[7], F.regexp_extract('AGEP Age', r'\\d+', 0)) \\\n",
    "                 .select(*columns)\n",
    "                \n",
    "age_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>postcode</th><th>total_parttime_or_fulltime_students</th></tr>\n",
       "<tr><td>2000</td><td>8101</td></tr>\n",
       "<tr><td>2006</td><td>1332</td></tr>\n",
       "<tr><td>2007</td><td>4008</td></tr>\n",
       "<tr><td>2008</td><td>5147</td></tr>\n",
       "<tr><td>2009</td><td>1726</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----------------------------------+\n",
       "|postcode|total_parttime_or_fulltime_students|\n",
       "+--------+-----------------------------------+\n",
       "|    2000|                               8101|\n",
       "|    2006|                               1332|\n",
       "|    2007|                               4008|\n",
       "|    2008|                               5147|\n",
       "|    2009|                               1726|\n",
       "+--------+-----------------------------------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_sdf = education_sdf.withColumn(\"postcode\", F.regexp_extract(\"postcode\", r'\\d+', 0)) \\\n",
    "                           .withColumnRenamed(\"total\", \"total_parttime_or_fulltime_students\") \\\n",
    "                           .select(\"postcode\", \"total_parttime_or_fulltime_students\")\n",
    "\n",
    "student_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>postcode</th><th>median_salary</th></tr>\n",
       "<tr><td>2000</td><td>575.0</td></tr>\n",
       "<tr><td>2006</td><td>75.0</td></tr>\n",
       "<tr><td>2007</td><td>350.0</td></tr>\n",
       "<tr><td>2008</td><td>575.0</td></tr>\n",
       "<tr><td>2009</td><td>1125.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-------------+\n",
       "|postcode|median_salary|\n",
       "+--------+-------------+\n",
       "|    2000|        575.0|\n",
       "|    2006|         75.0|\n",
       "|    2007|        350.0|\n",
       "|    2008|        575.0|\n",
       "|    2009|       1125.0|\n",
       "+--------+-------------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_sdf = spark.read.option(\"header\", True).csv(\"../data/raw/income_cleaned.csv\") \\\n",
    "                                              .select(\"postcode\", \"median_salary\")\n",
    "income_sdf.limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(column_name):\n",
    "   return F.mean(column_name).alias(\"mean_\" + column_name)\n",
    "\n",
    "def preprocessing_pipeline(dlist):\n",
    "    \"\"\"\n",
    "    preprocess all dataframe in the list\n",
    "        parameters: \n",
    "                   a list of dataframes\n",
    "        returns:\n",
    "                a generator of preprocessed dataframes\n",
    "    \"\"\"\n",
    "    for data in dlist:\n",
    "        # join persona data\n",
    "        data = data.join(income_sdf, \"postcode\", \"left\") \\\n",
    "                   .join(student_sdf, \"postcode\", \"left\") \\\n",
    "                   .join(age_sdf, \"postcode\", \"left\")\n",
    "\n",
    "        # remove rows contain null in persona\n",
    "        data = data.filter(F.col(\"median_salary\").isNotNull() \\\n",
    "                         | F.col(\"sub_total\").isNotNull() \\\n",
    "                         | F.col(\"total_parttime_or_fulltime_students\").isNotNull())\n",
    "\n",
    "        # take the mean of all persona\n",
    "        agg_data = data.groupBy(\"merchant_abn\") \\\n",
    "                       .agg(\n",
    "                            mean(\"median_salary\"),\n",
    "                            mean(\"total_parttime_or_fulltime_students\"),\n",
    "                            *[mean(name) for name in age_group]\n",
    "                            )\n",
    "        yield agg_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>mean_median_salary</th><th>mean_total_parttime_or_fulltime_students</th><th>mean_sub_total</th><th>mean_18_24</th><th>mean_25_34</th><th>mean_35_44</th><th>mean_45_54</th><th>mean_55_64</th><th>mean_65_plus</th></tr>\n",
       "<tr><td>34440496342</td><td>665.3571428571429</td><td>726.0285714285715</td><td>8046.771428571428</td><td>0.09616178597603435</td><td>0.14638469969797188</td><td>0.15608870164698682</td><td>0.1735831056885002</td><td>0.20771864696238573</td><td>0.220063060028121</td></tr>\n",
       "<tr><td>15613631617</td><td>647.4765258215963</td><td>635.1502347417841</td><td>6140.830985915493</td><td>0.09355564743741474</td><td>0.14970744876770364</td><td>0.15654891609964974</td><td>0.17981347180449017</td><td>0.1928799103803407</td><td>0.22749460551040104</td></tr>\n",
       "<tr><td>83412691377</td><td>665.4689608636977</td><td>658.808439383791</td><td>6706.924426450742</td><td>0.10427259065156969</td><td>0.15142024706844687</td><td>0.15652496789966566</td><td>0.18378714204466093</td><td>0.1838697186090033</td><td>0.22012533372665358</td></tr>\n",
       "<tr><td>24406529929</td><td>661.9674887892377</td><td>613.1066666666667</td><td>6236.961883408072</td><td>0.09703010735768407</td><td>0.1508463018793074</td><td>0.15552580740901656</td><td>0.18518170229690945</td><td>0.18534575633732567</td><td>0.22607032471975688</td></tr>\n",
       "<tr><td>73256306726</td><td>660.6919642857143</td><td>703.9039145907474</td><td>7043.998214285714</td><td>0.09931809556504945</td><td>0.14988948980853775</td><td>0.1557895084700852</td><td>0.187349726576246</td><td>0.1821697535401777</td><td>0.22548342603990384</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+------------------+----------------------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
       "|merchant_abn|mean_median_salary|mean_total_parttime_or_fulltime_students|   mean_sub_total|         mean_18_24|         mean_25_34|         mean_35_44|         mean_45_54|         mean_55_64|       mean_65_plus|\n",
       "+------------+------------------+----------------------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+\n",
       "| 34440496342| 665.3571428571429|                       726.0285714285715|8046.771428571428|0.09616178597603435|0.14638469969797188|0.15608870164698682| 0.1735831056885002|0.20771864696238573|  0.220063060028121|\n",
       "| 15613631617| 647.4765258215963|                       635.1502347417841|6140.830985915493|0.09355564743741474|0.14970744876770364|0.15654891609964974|0.17981347180449017| 0.1928799103803407|0.22749460551040104|\n",
       "| 83412691377| 665.4689608636977|                        658.808439383791|6706.924426450742|0.10427259065156969|0.15142024706844687|0.15652496789966566|0.18378714204466093| 0.1838697186090033|0.22012533372665358|\n",
       "| 24406529929| 661.9674887892377|                       613.1066666666667|6236.961883408072|0.09703010735768407| 0.1508463018793074|0.15552580740901656|0.18518170229690945|0.18534575633732567|0.22607032471975688|\n",
       "| 73256306726| 660.6919642857143|                       703.9039145907474|7043.998214285714|0.09931809556504945|0.14988948980853775| 0.1557895084700852|  0.187349726576246| 0.1821697535401777|0.22548342603990384|\n",
       "+------------+------------------+----------------------------------------+-----------------+-------------------+-------------------+-------------------+-------------------+-------------------+-------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_sdf = spark.read.parquet(\"../data/curated/transactions_withoutfraud\") \\\n",
    "                            .drop('user_id2',\n",
    "                                  'order_datetime2',\n",
    "                                  'fraud rate',\n",
    "                                  'fraud2',\n",
    "                                  'user_id3',\n",
    "                                  'order_datetime3',\n",
    "                                  'fraud_probability',\n",
    "                                  'fraud3')\n",
    "\n",
    "# training data is the part of data before the first fortnight of 2022\n",
    "train_transaction_sdf = transaction_sdf.where(F.col(\"order_datetime\") <= \"2022-1-16\")\n",
    "\n",
    "data_list = [transaction_sdf, train_transaction_sdf]\n",
    "\n",
    "data_list = list(preprocessing_pipeline(data_list))\n",
    "\n",
    "data_list[0].limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_persona_score(dlist, filenames):\n",
    "    \"\"\"\n",
    "    compute persona scores for all merchants in a dataframe and write the result to a .csv file\n",
    "    parameters:\n",
    "               dlist (list): a list of dataframes\n",
    "               filenames (list): a list of filenames in which the final results will be written\n",
    "    return:\n",
    "           a generator of dataframes containing merchant ABN and persona score\n",
    "    \"\"\"\n",
    "    for data, filename in zip(dlist, filenames):\n",
    "        data = data.withColumn(\"pop_index\",\n",
    "                                0.26*F.col(\"mean_18_24\") + \n",
    "                                0.35*F.col(\"mean_25_34\") + \n",
    "                                0.20*F.col(\"mean_35_44\") + \n",
    "                                0.12*F.col(\"mean_45_54\") + \n",
    "                                0.05*F.col(\"mean_55_64\") +\n",
    "                                0.01*F.col(\"mean_65_plus\")\n",
    "                                )\n",
    "                                \n",
    "        data = data.select(\"merchant_abn\",\n",
    "                            \"mean_median_salary\", \n",
    "                            \"mean_total_parttime_or_fulltime_students\",\n",
    "                            \"pop_index\",\n",
    "                            \"mean_sub_total\")\n",
    "\n",
    "        for col in data.columns[1:]:\n",
    "            col_max = data.agg({col:\"max\"}).collect()[0][0]\n",
    "            col_min = data.agg({col:\"min\"}).collect()[0][0]\n",
    "            data = data.withColumn(col, (F.col(col)-F.lit(col_min)) / (F.lit(col_max)-F.lit(col_min)) )\n",
    "            data = data.withColumnRenamed(col, \"normalized_\"+col)\n",
    "        \n",
    "\n",
    "        data = data.withColumn(\"persona_score\",\n",
    "                               F.col(\"normalized_mean_median_salary\") *\n",
    "                               F.col(\"normalized_mean_total_parttime_or_fulltime_students\") *\n",
    "                               F.col(\"normalized_pop_index\") *\n",
    "                               F.col(\"normalized_mean_sub_total\")\n",
    "                               )\n",
    "        \n",
    "        data.select(\"merchant_abn\", \"persona_score\").toPandas().to_csv(\"../data/curated\" + filename, index=False)\n",
    "        \n",
    "        print(\"%s is done\" % filename)\n",
    "\n",
    "        yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_persona_score.csv is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_persona_score.csv is done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>merchant_abn</th><th>normalized_mean_median_salary</th><th>normalized_mean_total_parttime_or_fulltime_students</th><th>normalized_pop_index</th><th>normalized_mean_sub_total</th><th>persona_score</th></tr>\n",
       "<tr><td>34440496342</td><td>0.3808755760368664</td><td>0.07081133048167088</td><td>0.40127655364434606</td><td>0.1677114736127164</td><td>0.001815066069980...</td></tr>\n",
       "<tr><td>15613631617</td><td>0.3693396940784492</td><td>0.061947745512706924</td><td>0.40449603274382717</td><td>0.1279679494936086</td><td>0.001184314286334...</td></tr>\n",
       "<tr><td>83412691377</td><td>0.3809477166862566</td><td>0.06425518768982649</td><td>0.4208215090973179</td><td>0.13977238356932903</td><td>0.001439769178086...</td></tr>\n",
       "<tr><td>24406529929</td><td>0.37868870244466946</td><td>0.05979778276276862</td><td>0.41110986660983145</td><td>0.12997251404220686</td><td>0.001209976259968398</td></tr>\n",
       "<tr><td>73256306726</td><td>0.37786578341013827</td><td>0.06865345894769798</td><td>0.41310897548428593</td><td>0.14680119722841176</td><td>0.001573237242596...</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+-----------------------------+---------------------------------------------------+--------------------+-------------------------+--------------------+\n",
       "|merchant_abn|normalized_mean_median_salary|normalized_mean_total_parttime_or_fulltime_students|normalized_pop_index|normalized_mean_sub_total|       persona_score|\n",
       "+------------+-----------------------------+---------------------------------------------------+--------------------+-------------------------+--------------------+\n",
       "| 34440496342|           0.3808755760368664|                                0.07081133048167088| 0.40127655364434606|       0.1677114736127164|0.001815066069980...|\n",
       "| 15613631617|           0.3693396940784492|                               0.061947745512706924| 0.40449603274382717|       0.1279679494936086|0.001184314286334...|\n",
       "| 83412691377|           0.3809477166862566|                                0.06425518768982649|  0.4208215090973179|      0.13977238356932903|0.001439769178086...|\n",
       "| 24406529929|          0.37868870244466946|                                0.05979778276276862| 0.41110986660983145|      0.12997251404220686|0.001209976259968398|\n",
       "| 73256306726|          0.37786578341013827|                                0.06865345894769798| 0.41310897548428593|      0.14680119722841176|0.001573237242596...|\n",
       "+------------+-----------------------------+---------------------------------------------------+--------------------+-------------------------+--------------------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"full_persona_score.csv\", \"trained_persona_score.csv\"]\n",
    "list(compute_persona_score(data_list, filenames))[0].limit(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
