{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buy Now, Pay Later Project - Group 8\n",
    "# Applied Data Science (MAST30034)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. Problem overview  <br><br>\n",
    "    1.1&nbsp;&nbsp; Overview of our insight in producing the solution <br><br>\n",
    "2. Data  <br><br>\n",
    "    2.1&nbsp;&nbsp; Synthetically generated data provided by the teaching team  \n",
    "    2.2&nbsp;&nbsp; External dataset (obtain from the Australian Bureau of Statistics (ABS)) <br><br>\n",
    "3. Understanding data and cleaning  <br><br>\n",
    "    3.1&nbsp;&nbsp; General overview on synthesis datasets  \n",
    "    3.2&nbsp;&nbsp; Cleaning the synthetic datasets    \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.2.3&nbsp;&nbsp;&nbsp;&nbsp; Resolving the missing merchants' details  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.3.1&nbsp;&nbsp;&nbsp;&nbsp; Classification (not successful)    \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2.3.2&nbsp;&nbsp;&nbsp;&nbsp; Clustering and imputation  \n",
    "    3.3&nbsp;&nbsp; Dealing with fraudulent data  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.3.1&nbsp;&nbsp;&nbsp;&nbsp; Implementing a merchant fraud detection model (not successful)  \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp; 3.3.2&nbsp;&nbsp;&nbsp;&nbsp; Implementing a consumer fraud detection model  \n",
    "    3.4&nbsp;&nbsp; General overview on external datasets  \n",
    "    3.5&nbsp;&nbsp; Cleaning the external datasets  <br><br>\n",
    "4. Determining segments of merchant<br><br>\n",
    "5. Ranking model assumptions (usage of variables and its intuition)<br><br>\n",
    "6. Result of model<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary library and run spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"preprocessing of taxi data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"15g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem overview \n",
    "\n",
    "A generic Buy Now, Pay Later (BNPL) firm has begun offering \n",
    "a new “Pay in 5 Installments” feature. Merchants are looking to form a partnership as it may boost their customer base, the BNPL firm in return gets a small percentage of revenue to cover their operating cost. However, the BNPL firm can only onboard at most 100 < X number of merchants every year due to limited resources. Hence, we will design a ranking system for the merchants to assist the firm in selecting merchants that they should accept.\n",
    "\n",
    "### 1.1 Overview of our insight in producing the solution\n",
    "\n",
    "As a **firm that has just begun their business**, we believe that their business goals is to **earn profit while \n",
    "maintaining a long-term establishment of their business**. Hence, when selecting merchants we believe that the monetary worth of cashflows which a merchant can bring for the BNPL firm is not the sole criterion for this new firm picking business partners.\n",
    "\n",
    "High returns may come with high risks, merchants could be making a 100,000 in a month and is out of business for the rest of the year, this could possibly impact the cash flow in the BNPL firm. As a new establish firm may not have a stable cash flow, this may hinder the objective of staying in business for a long-term and create financial risk, hence, we aim to select merchants that provide a **stable return**.\n",
    "\n",
    "Also, as a newly establish firm, we believe that the firm **may not have a large and strong consumer base that uses their services**. Hence, merchants with a young customer demographic and other features (explained in Ranking model assumption) are also consider when creating a ranking system for the merchant.\n",
    "\n",
    "Thus, our solution is based on our domain knowledge in Finance and Economics which give intutions of what goals the firm may have, and hopes to **maintain a stable profit to allow the firm to stay in operation but also help expand the firm for better revenues in the future**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 2.1 Synthetically generated data provided by the teaching team\n",
    "These are data related to the BNPL firm.\n",
    "- Merchant data (merchants that are to be consider for selections)\n",
    "    - Contains information about merchants including merchant ABN, merchant name, take rate, product description, and revenue level.\n",
    "    - Each data entry is an unique merchant as define by their unique merchant ABN. <br><br> \n",
    "- Consumer data (consumers that may have a purchase in one of the merchants)\n",
    "    - Contains information about consumers including consumer_id, name, address\tstate, postcode, and gender.\n",
    "    - Each data entry is an unique consumer as define by their unique consumer ID. <br><br> \n",
    "- Transaction data (raw transactions of merchants)\n",
    "    - Contains information about transactions of merchant including user_id, merchant_abn, dollar_value, order_id,\tand order_datetime. \n",
    "    - Each data entry is an unique order. <br><br> \n",
    "- Consumer details (A conversion table to allow Transaction to join with consumers)\n",
    "    - Two columns, user_id and consumer_id. <br><br> \n",
    "- Merchant fraud probability data\n",
    "    - Contains merchant_abn, order_datetime, fraud probability\n",
    "    - Each data entry represent the chance the entire batch of transaction done with that merchant on that day could be considered fraudulent. <br><br> \n",
    "- Consumer fraud probability data\n",
    "    - Contains user_id, order_datetime, fraud probability\n",
    "    - Each data entry represent the chance the entire batch of transaction done by that consumer on that day could be considered fraudulent.\n",
    "\n",
    "* ** As the third set of transactions data were labelled to end at August 20th 2022, but actual transactions dated up to October 2022, it was decided to remove all transactions after August 20th 2022 to keep in line with the spec. This is just like treating data after August 20th 2022 as input errors ** *\n",
    "\n",
    "### 2.2 External dataset (obtain from the Australian Bureau of Statistics (ABS))\n",
    "These are external datasets that provide demographic statistics about a post code in Australia, as the actual real-life component of the provided datasets are the postcodes of the consumers.\n",
    "- 2016 Age data \n",
    "    - Contains the reported count of age 0 to 115, and the total reported population count.\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "- 2016 Education data\n",
    "    - Contains the reported count of students, part-time, full-time, TAFE, total students\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "- Income data\n",
    "    - Contains the weekly total personal income counts under income categories ranging from $1 to $3000 or more, incrementing by $150.\n",
    "    - Each data entry is an unique postcode location. <br><br> \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding data and cleaning\n",
    "### 3.1 General overview on synthesis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# reading in the data\n",
    "transact_data1 = spark.read.parquet(\"../data/tables/transactions_20210228_20210827_snapshot/\")\n",
    "transact_data2 = spark.read.parquet(\"../data/tables/transactions_20210828_20220227_snapshot/\")\n",
    "transact_data3 = spark.read.parquet(\"../data/tables/transactions_20220228_20220828_snapshot/\")\n",
    "transactions_sdf = transact_data1.union(transact_data2)\n",
    "transactions_sdf = transactions_sdf.union(transact_data3)\n",
    "merchant_sdf = spark.read.parquet(\"../data/tables/tbl_merchants.parquet\")\n",
    "consumer_sdf = spark.read.option(\"header\",True) \\\n",
    "                         .option(\"inferSchema\",True) \\\n",
    "                         .options(delimiter='|') \\\n",
    "                         .csv(\"../data/tables/tbl_consumer.csv\")\n",
    "consumer_fraud = spark.read.option(\"header\",True).csv('../data/tables/consumer_fraud_probability.csv', )\n",
    "merchant_fraud = spark.read.option(\"header\",True).csv('../data/tables/merchant_fraud_probability.csv', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick look at the dataset sizes and what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14195505 entries of the Transactions dataset\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|user_id|merchant_abn|      dollar_value|            order_id|order_datetime|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "|  18478| 62191208634|63.255848959735246|949a63c8-29f7-4ab...|    2021-08-20|\n",
      "+-------+------------+------------------+--------------------+--------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 4026 entries of the Merchants dataset\n",
      "+-------------+--------------------+------------+\n",
      "|         name|                tags|merchant_abn|\n",
      "+-------------+--------------------+------------+\n",
      "|Felis Limited|((furniture, home...| 10023283211|\n",
      "+-------------+--------------------+------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 499999 entries of the Consumers dataset\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|            name|             address|state|postcode|gender|consumer_id|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "|Yolanda Williams|413 Haney Gardens...|   WA|    6935|Female|    1195503|\n",
      "+----------------+--------------------+-----+--------+------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the first row of the datasets\n",
    "print(f'There are {transactions_sdf.count()} entries of the Transactions dataset')\n",
    "print(transactions_sdf.show(1))\n",
    "print(f'There are {merchant_sdf.count()} entries of the Merchants dataset')\n",
    "print(merchant_sdf.show(1))\n",
    "print(f'There are {consumer_sdf.count()} entries of the Consumers dataset')\n",
    "print(consumer_sdf.show(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 34864 entries of the Consumer fraud probability dataset\n",
      "+-------+--------------+-----------------+\n",
      "|user_id|order_datetime|fraud_probability|\n",
      "+-------+--------------+-----------------+\n",
      "|   6228|    2021-12-19| 97.6298077657765|\n",
      "+-------+--------------+-----------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n",
      "There are 114 entries of the Merchant fraud probability dataset\n",
      "+------------+--------------+------------------+\n",
      "|merchant_abn|order_datetime| fraud_probability|\n",
      "+------------+--------------+------------------+\n",
      "| 19492220327|    2021-11-28|44.403658647495355|\n",
      "+------------+--------------+------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the first row of the datasets\n",
    "print(f'There are {consumer_fraud.count()} entries of the Consumer fraud probability dataset')\n",
    "print(consumer_fraud.show(1))\n",
    "print(f'There are {merchant_fraud.count()} entries of the Merchant fraud probability dataset')\n",
    "print(merchant_fraud.show(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cleaning the synthetic datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merchant dataset\n",
    "From the presented row above of the merchant dataset, it is found that the tags column contains information about product description, revenue level, and take rate. Such information is extracted and treated as separate columns, for better visual and easier code handling for later analysis and feature engineering.  \n",
    "\n",
    "#### Transaction dataset\n",
    "The transactions are consider to be within the time range of 2021-02-28 to 2022-08-28. However, it is found that the dataset contains transactions past the time range and such transactions are removed.\n",
    "\n",
    "#### Joining the merchant, consumer, and transaction dataset to check if there are any missing information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "|user_id|merchant_abn|dollar_value|order_id|merchant_name|prod_desc|revenue_level|take_rate|consumer_name|address|state|postcode|gender|consumer_id|\n",
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "|      0|           0|           0|       0|       149228|   149228|       149228|   149228|            0|      0|    0|       0|     0|          0|\n",
      "+-------+------------+------------+--------+-------------+---------+-------------+---------+-------------+-------+-----+--------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing if there are any missing values in the columns\n",
    "transaction_20210228_20210827_missings_sdf = spark.read.parquet(\"../data/curated/transactions_20210228_20210827_all_details_missing_counts\")\n",
    "transaction_20210228_20210827_missings_sdf.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is found that there are merchants with no information about them, however, we decided not to discard such merchants as they have transaction and customer records that may be worth selecting for the firm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Resolving the missing merchants' details\n",
    "We first decided to create a classification model that is able to help classify the missing merchant details, however, the model's accuracy was too low. Hence, we resolved with clustering the unknown merchants into the known merchant clusters and performed a mean imputation for take rate as it is the variable we require for further calculations and investigation for the ranking system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3.1 Classification (not successful)    \n",
    "\n",
    "**Objective**: Predict product description, revenue level and take rate of the missing merchants "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the markdown cell below to see the classification pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification pipeline**:  \n",
    " 0. Preliminary Data Analysis  \n",
    " 1. Data Engineering\n",
    "  * Mostly done in ETL\n",
    "    * Encode revenue level into integer value, e.g. 1, 2, 3, 4, 5\n",
    "    * Clean the prod_desc (has been updated in ETL)\n",
    "  * Need one curated dataset for modeling product description and one dataset for modeling revenue level and take rate\n",
    " 2. Feature Engineering\n",
    "  * Aggregate data to produce more useful features for modeling revenue level and take rate\n",
    "  * Recommended features for prod_desc: dollar value, user id and order datetime\n",
    "  * Recommended features for revenue level and take rate: monthly average revenue,  monthly average number of orders, monthly average number of distinct customers, average revenue per order, median revenue, variance of dollar amount\n",
    " 3. Data Modeling\n",
    "  * Choice of classification model: XGBClassifier, RandomForest, Naive Bayes(Last resort)\n",
    "  * Choice of regression model: Linear regression, XGBregressor\n",
    "  * Fitting and Tuning model to achieve optimal performance \n",
    " 4. Model Validation\n",
    " * Metrics:\n",
    "    * Categorical(prod_desc and revenue_level): \n",
    "      * Accuracy\n",
    "      * f1 score\n",
    "    * Continuous(take_rate):\n",
    "      * RMSE\n",
    " * Visualization:\n",
    "    * Categorical:\n",
    "      * learning curve\n",
    "      * ROC curve\n",
    "      * confusion matrix \n",
    "    * Continuous:\n",
    "      * RMSE vs. fitted value\n",
    " 5. Model deployment\n",
    "   * Use the prediction to impute missing information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the models have poor performance in terms of accuracy/RMSE, it is not feasible to deploy them in an imputation process. From our perspectives, tuning the model will be ultimately a waste of time because it will only refine our model instead of improving it significantly. <u>Therefore, we resolve into clustering.</u> We believe that the merchant are not fully represented in regards to take rate, product description, and revenue level, under our engineered features.\n",
    "\n",
    "To see the classification models and their performance click [classify_missing_merchants](./A_Y_H_classify_missing_merchants.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3.2 Clustering and imputation \n",
    "**Objective**: Perform clustering on the merchants to obtain 3 to 5 clusters, which can be used for market segmentation and take rate imputation\n",
    "\n",
    "We clustered the merchants based on their consumer base, average monthly order, average monthly revenue. Given we only have transaction and consumer data on the unknown merchants, we believe that the 3 features we created can help group similar merchants based on the business sizes evaluated by the features. We utilized **K-means, MeanShift, DBSCAN, Gausian Mixutre Model**, and evaluated their performance under **Silhouette Coefficient, Calinski-Harabasz Index, and Davies-Bouldin Index**. We found that the Gausian Mixture model performed the best. Below presents the clusters for a quick visualization,  <br><br>\n",
    "<img src=\"../plots/GMMclusters.png\" width=\"1000\" class=\"center\"> <br><br>\n",
    "\n",
    "After creating the clusters, **we fit the unknown merchants into the clusters and impute the take rates of such unknown merchants by the mean of the take rates of their respective clusters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dealing with Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BNPL buisiness model can be understood as: the merchants gain extra revenue from impulse spending because of the low upfront cost, and is guarenteed the full amount of the purchase (less the take rate) is received immediately, for the cost of the take rate; the BNPL firm receives the take rate, with the cost being operational cost, lost interest rate on later instalments, and risk of consumers not paying back (default risk).\n",
    "\n",
    "Two datasets were provided by the teaching staff, the first consisting of a small sample of merchants-day and the second consisting of a small sample of consumer-day, labelled with probability of fraud. It was assumed that if i.e. a consumer-day was 'fraudulant', then all its transacitons on the day should be dsicarded. \n",
    "\n",
    "Although not every transaction may have been fradulant, the cost of a fraudulant transaction that is bought upon the BNPL company should be greater than the transaction sum itself (i.e. it would have to cough up (1-take rate) * transaction because under the business model it bears the transaction risk in return for the take rate); hence, if a consumer-day was considered fradulant, then all transactions on that day would be thrown out (i.e. could have earned money on other transactions - but those would be used to balance out the cost brought by the fraudulant transactions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1 Dealing with consumer fraud\n",
    "\n",
    "We treated this problem as a supervised learning problem, with labels being predicted fraud probability. We chose to use the continuous predicting model of random forest regressor.\n",
    "\n",
    "We treated each consumer-day (i.e. each row in the fraud dataset) as an instance, and engineered variables such as the average transaction amount on that day by that consumer; the sd of transaction amounts on the day by that customer; the number of transactions they had; and number of distinct stores they shopped at. All these were derived by joining fraud dataset with transaction dataset and then aggregating.\n",
    "\n",
    "Four other variables were also engineered: i.e. number of distinct stores they shopped at on day of being labelled / average number of distinct stores they shopped at in the past days when they made at least one transaction. The same idea was implemented for the other three variables. The latter 4 variables are expected to give a ratio that standardises each consumer-day by the consumer's historic behaviour, to make different consumers more comparable. They are denoted by appending the word 'ratio' behind the name.\n",
    "\n",
    "Ultimately, 'transaction amount per order ratio', 'transaction amount per order', 'sd of transaction amounts on the day', 'sd of transaction amounts on the day ratio' were chosen as variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>max_features</th>\n",
       "      <th>ccp_alpha</th>\n",
       "      <th>training_accuracy</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>testing_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>18</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.91441</td>\n",
       "      <td>0.798436</td>\n",
       "      <td>0.798915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  n_estimators  max_depth  max_samples  max_features  \\\n",
       "757           0           150         18          0.5          0.75   \n",
       "\n",
       "     ccp_alpha  training_accuracy  validation_accuracy  testing_accuracy  \n",
       "757      0.001            0.91441             0.798436          0.798915  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr_tuning = pd.read_csv('../data/tuning/RFR_brute.csv')\n",
    "rfr_tuning.sort_values(['validation_accuracy'], ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, the best combination of hyperparameters gave validation R^2 and testing R^2 of 0.798, which are very good results.\n",
    "\n",
    "However, upon inspecting the predicted values (on the whole dataset), it was found that a lot of the consumer-day had extremely low predicted fraud probability (around 9%), so the predicted results were only good for ranking as opposed to actual intuition. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_fraud = pd.read_csv('../data/curated/fraud/final_fraud_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.394051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.920289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.287148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.411906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.362188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud rate\n",
       "mean    9.394051\n",
       "std     0.920289\n",
       "min     9.287148\n",
       "25%     9.287148\n",
       "50%     9.287148\n",
       "75%     9.411906\n",
       "max    85.362188"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_fraud[['fraud rate']].describe()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, it was decided to only remove about 0.1% of the transactions and hence the threshold for fradulant data was set at 20% predicted fraud. The 0.1% came about because we believed anything less would be so insignificant that this fraud detection task would not be worth doing; while any higher would mean the BNPL firm loses money (because the take rate margin are in general so slim)\n",
    "\n",
    "Although this outcome is not as good as i.e. there was a more spread out distribution and the cutoff rate could be higher, in the end the threshold was always going to be manually determined, and practically does not make much of a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../plots/KDE_sample_fraud_rate.jpg\" width=\"250\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../plots/boxplot_sample_fraud_rate.jpg\" width=\"250\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2 Dealing with merchant fraud\n",
    "\n",
    "Although the exact process could be repeated for the merchant fraud, we deemed it unviable and unnecessary because\n",
    "\n",
    "1. there were only 114 rows of data with labels - not nearly enough to train a model given our method of treating each merchant-day as an instance. Inaccurate models risk throwing out too many transactions that were in reality not fraud\n",
    "\n",
    "2. we already have a sufficient model dealing with fraud for consumers that would be run over all data, so a merchatn fraud model would be complimentary rather than a necessity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3 Final removal\n",
    "\n",
    "Just running the consumer fraud model over the entire dataset, approximately 16000 of the 14 million transactions were removed. \n",
    "\n",
    "14179422 transactions were left after the removal of fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 General overview of the external datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "income_sdf = spark.read.option(\"header\",True).csv('../data/curated/income.csv')\n",
    "age_sdf = spark.read.option(\"header\",True).csv('../data/curated/2016_age.csv')\n",
    "education_sdf = spark.read.option(\"header\",True).csv('../data/curated/2016_education.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2653 entries of the income dataset\n",
      "root\n",
      " |-- INCP Total Personal Income (weekly): string (nullable = true)\n",
      " |-- Negative income: string (nullable = true)\n",
      " |-- Nil income: string (nullable = true)\n",
      " |-- $1-$149 ($1-$7,799): string (nullable = true)\n",
      " |-- $150-$299 ($7,800-$15,599): string (nullable = true)\n",
      " |-- $300-$399 ($15,600-$20,799): string (nullable = true)\n",
      " |-- $400-$499 ($20,800-$25,999): string (nullable = true)\n",
      " |-- $500-$649 ($26,000-$33,799): string (nullable = true)\n",
      " |-- $650-$799 ($33,800-$41,599): string (nullable = true)\n",
      " |-- $800-$999 ($41,600-$51,999): string (nullable = true)\n",
      " |-- $1,000-$1,249 ($52,000-$64,999): string (nullable = true)\n",
      " |-- $1,250-$1,499 ($65,000-$77,999): string (nullable = true)\n",
      " |-- $1,500-$1,749 ($78,000-$90,999): string (nullable = true)\n",
      " |-- $1,750-$1,999 ($91,000-$103,999): string (nullable = true)\n",
      " |-- $2,000-$2,999 ($104,000-$155,999): string (nullable = true)\n",
      " |-- $3,000 or more ($156,000 or more): string (nullable = true)\n",
      " |-- Not stated: string (nullable = true)\n",
      " |-- Not applicable: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the income dataset\n",
    "print(f'There are {income_sdf.count()} entries of the income dataset')\n",
    "print(income_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2653 entries of the age dataset\n",
      "root\n",
      " |-- AGEP Age: string (nullable = true)\n",
      " |-- 0: string (nullable = true)\n",
      " |-- 1: string (nullable = true)\n",
      " |-- 2: string (nullable = true)\n",
      " |-- 3: string (nullable = true)\n",
      " |-- 4: string (nullable = true)\n",
      " |-- 5: string (nullable = true)\n",
      " |-- 6: string (nullable = true)\n",
      " |-- 7: string (nullable = true)\n",
      " |-- 8: string (nullable = true)\n",
      " |-- 9: string (nullable = true)\n",
      " |-- 10: string (nullable = true)\n",
      " |-- 11: string (nullable = true)\n",
      " |-- 12: string (nullable = true)\n",
      " |-- 13: string (nullable = true)\n",
      " |-- 14: string (nullable = true)\n",
      " |-- 15: string (nullable = true)\n",
      " |-- 16: string (nullable = true)\n",
      " |-- 17: string (nullable = true)\n",
      " |-- 18: string (nullable = true)\n",
      " |-- 19: string (nullable = true)\n",
      " |-- 20: string (nullable = true)\n",
      " |-- 21: string (nullable = true)\n",
      " |-- 22: string (nullable = true)\n",
      " |-- 23: string (nullable = true)\n",
      " |-- 24: string (nullable = true)\n",
      " |-- 25: string (nullable = true)\n",
      " |-- 26: string (nullable = true)\n",
      " |-- 27: string (nullable = true)\n",
      " |-- 28: string (nullable = true)\n",
      " |-- 29: string (nullable = true)\n",
      " |-- 30: string (nullable = true)\n",
      " |-- 31: string (nullable = true)\n",
      " |-- 32: string (nullable = true)\n",
      " |-- 33: string (nullable = true)\n",
      " |-- 34: string (nullable = true)\n",
      " |-- 35: string (nullable = true)\n",
      " |-- 36: string (nullable = true)\n",
      " |-- 37: string (nullable = true)\n",
      " |-- 38: string (nullable = true)\n",
      " |-- 39: string (nullable = true)\n",
      " |-- 40: string (nullable = true)\n",
      " |-- 41: string (nullable = true)\n",
      " |-- 42: string (nullable = true)\n",
      " |-- 43: string (nullable = true)\n",
      " |-- 44: string (nullable = true)\n",
      " |-- 45: string (nullable = true)\n",
      " |-- 46: string (nullable = true)\n",
      " |-- 47: string (nullable = true)\n",
      " |-- 48: string (nullable = true)\n",
      " |-- 49: string (nullable = true)\n",
      " |-- 50: string (nullable = true)\n",
      " |-- 51: string (nullable = true)\n",
      " |-- 52: string (nullable = true)\n",
      " |-- 53: string (nullable = true)\n",
      " |-- 54: string (nullable = true)\n",
      " |-- 55: string (nullable = true)\n",
      " |-- 56: string (nullable = true)\n",
      " |-- 57: string (nullable = true)\n",
      " |-- 58: string (nullable = true)\n",
      " |-- 59: string (nullable = true)\n",
      " |-- 60: string (nullable = true)\n",
      " |-- 61: string (nullable = true)\n",
      " |-- 62: string (nullable = true)\n",
      " |-- 63: string (nullable = true)\n",
      " |-- 64: string (nullable = true)\n",
      " |-- 65: string (nullable = true)\n",
      " |-- 66: string (nullable = true)\n",
      " |-- 67: string (nullable = true)\n",
      " |-- 68: string (nullable = true)\n",
      " |-- 69: string (nullable = true)\n",
      " |-- 70: string (nullable = true)\n",
      " |-- 71: string (nullable = true)\n",
      " |-- 72: string (nullable = true)\n",
      " |-- 73: string (nullable = true)\n",
      " |-- 74: string (nullable = true)\n",
      " |-- 75: string (nullable = true)\n",
      " |-- 76: string (nullable = true)\n",
      " |-- 77: string (nullable = true)\n",
      " |-- 78: string (nullable = true)\n",
      " |-- 79: string (nullable = true)\n",
      " |-- 80: string (nullable = true)\n",
      " |-- 81: string (nullable = true)\n",
      " |-- 82: string (nullable = true)\n",
      " |-- 83: string (nullable = true)\n",
      " |-- 84: string (nullable = true)\n",
      " |-- 85: string (nullable = true)\n",
      " |-- 86: string (nullable = true)\n",
      " |-- 87: string (nullable = true)\n",
      " |-- 88: string (nullable = true)\n",
      " |-- 89: string (nullable = true)\n",
      " |-- 90: string (nullable = true)\n",
      " |-- 91: string (nullable = true)\n",
      " |-- 92: string (nullable = true)\n",
      " |-- 93: string (nullable = true)\n",
      " |-- 94: string (nullable = true)\n",
      " |-- 95: string (nullable = true)\n",
      " |-- 96: string (nullable = true)\n",
      " |-- 97: string (nullable = true)\n",
      " |-- 98: string (nullable = true)\n",
      " |-- 99: string (nullable = true)\n",
      " |-- 100: string (nullable = true)\n",
      " |-- 101: string (nullable = true)\n",
      " |-- 102: string (nullable = true)\n",
      " |-- 103: string (nullable = true)\n",
      " |-- 104: string (nullable = true)\n",
      " |-- 105: string (nullable = true)\n",
      " |-- 106: string (nullable = true)\n",
      " |-- 107: string (nullable = true)\n",
      " |-- 108: string (nullable = true)\n",
      " |-- 109: string (nullable = true)\n",
      " |-- 110: string (nullable = true)\n",
      " |-- 111: string (nullable = true)\n",
      " |-- 112: string (nullable = true)\n",
      " |-- 113: string (nullable = true)\n",
      " |-- 114: string (nullable = true)\n",
      " |-- 115: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the age dataset\n",
    "print(f'There are {age_sdf.count()} entries of the age dataset')\n",
    "print(age_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2668 entries of the education dataset\n",
      "root\n",
      " |-- postcode: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Part-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Part-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- Technical or Further Educ Inst (incl. TAFE Colleges): Full-time/Part-time student status not stated: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Part-time student: Aged 15-24 years: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Part-time student: Aged 25 years and over: string (nullable = true)\n",
      " |-- University or other Tertiary Institution: Full-time/Part-time student status not stated: string (nullable = true)\n",
      " |-- Other: Full-time student: string (nullable = true)\n",
      " |-- Other: Part-time student: string (nullable = true)\n",
      " |-- Total: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# printing the size and the columns of the education dataset\n",
    "print(f'There are {education_sdf.count()} entries of the education dataset')\n",
    "print(education_sdf.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Cleaning the external datasets\n",
    "\n",
    "We check for any missing values and string formatting issues that are presented in the data sets and found that are none, aggregation and feature engineering was done later in the calculations of the ranking persona feature variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background and intuition: \n",
    "\n",
    "The goal of our ranking model was to return a portfolio of 100 companies which maximise the Sharpe Ratio. The Sharpe Ratio is a finance concept quantifying risk compensation which for our problem equals to E( (revenue * take rate) of the whole portfolio ) / sd( (revenue * take rate) of the whole portfolio ). The purpose of using this metric is because as a company, having high incoming cashflow is of course predominantly good, but if high cashflows come with high variance, this could put the buisiness at financial risk, which brings along implicit bankruptcy costs etc; by using the Sharpe Ratio to evaluate the portfolio of 100 companies, we can guarentee that we have maximised the amount of incoming cashflow from merchant revenue * take rate for all the risk (standard deviation) we have chosen. \n",
    "\n",
    "Our ranking model consists a heuristic function, which is a linear function that returns the score for each merchant based on several variables. The top 100 ranking merchants would then be selected to be the final 100 merchants. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables used in the linear heuristc function are: \n",
    "1. Historic mean (revenue * take rate) of the firm\n",
    "2. Historic sd of (revenue * take rate) of the firm/Historic mean (revenue * take rate) of the firm\n",
    "3. Historic corr of (revenue * take rate) of the firm and (revenue & take rate) of all companies in the market\n",
    "4. Loyalty rate  \n",
    "    The loyalty variable is a variable design to measure a merchants consumer base, we wanted merchants with loyal customers that are staying with them, thus, when we select such merchant for partnerships, it is highly possible such consumers can be converted in to our customers.\n",
    "    By providing a after pay method, it is likely they would try to use it to purchase more frequently at their \"favorite\" store, thus, introduced to our firm's service and even use it to purchase in other merchants.\n",
    "5. Persona score \n",
    "    The persona score is a score given to a merchant based on its consumers demographic statistics.\n",
    "    Compose of 4 components:\n",
    "    - Age \n",
    "        Young is better, as they have the ability to communicate through social media and promote the firm, and are more willing to convert or accept the financial payment methods.\n",
    "    - Education\n",
    "        we wanted students because by reference (), many BNPL users are students\n",
    "    - Income\n",
    "        we wanted high income consumers, so they are able to repay or repay stably the buy now pay later installments, in the future\n",
    "    - Total population\n",
    "        wanted consumers coming from areas with high population.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Growth rate was attempted as a variable, but was found to be not useful\n",
    "\n",
    "*To calculate the sd of firms, company's transactions were grouped by fortnight*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of tuning coefficients for variables in linear function:\n",
    "\n",
    "0. Split our data into 23 fortnights for training and 13 fortnights for validation\n",
    "1. Iterate over different combinations of coefficients for each variable for the linear heuristic function\n",
    "2. Use this linear function to calculate the score for each merchant, and rank it\n",
    "3. Take the top 100 scoring merchants and form a portfolio, and then calculate its Sharpe Ratio in the validation set\n",
    "4. The set of combination of coefficients with the highest validation sharpe ratio will be the final coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions and alterations of financial theories\n",
    "\n",
    "- The 'market' which the correlation compares to here is not the most efficient portfolio that real stock market finance analysts use - they calculate correlation of a share to the 'market portfolio', but here because we do not have a 'risk free rate', nor have resources to calculate the efficient portfolio, thus we just use the portfolio of all companies together as our 'market'.\n",
    "\n",
    "- As stated above, we do not have a risk free rate; also we do not need to put in initial investment amount (it is like getting to invest in 100 stocks for free), so instead of using E(return rate) and sd(return rate) etc which what finance analysts do, we use E(revenue * take rate) and sd(revenue * take rate)\n",
    "\n",
    "- Also, in real finance, a portfolio would consist of different weighting of stocks (i.e. 1/2 money in stock A, 1/3 money in stock B and 1/6 money in stock C), and the sum of weights must add up to 1. However, here, our portfolio's 'weights' add up to 100, and each merchant's weight can only ever be 1. (alternatively can think of as weight = 1/100, but because we are dealing with E( return rate ) it is best to use w=1, sum(w_i) = 100)\n",
    "\n",
    "- in training our model, we also assume that the business transaction behaviour during the 'train' period and 'test' period are similar when a portfolio of multiple merchants are considered, and that the behaviour of the whole period is similar to the train and test \n",
    "\n",
    "- the act of using the same data (split into two segments) to tune up the model and then using the overall data to get a final result inherently causes overfit; but this risk/disadvantage is smaller than i.e. using a smaller section of unseen data to do final prediction. This is because the data provided only spans 18 months, which is 39 fortnights, and if splitting into three parts will likely hurt the model more than the overfit component. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Analysis\n",
    "\n",
    "We first see that the two fundamental characteristics which relate to our aim of stable growth: fortnightly mean cashflow and its scaled sd, shows significant differences between portfolio and non-portfolio merchants. Specifically, the within portfolio median of fortnightly mean cashflow at around 260k is much higher than that of the others at approximately 21k.\n",
    "\n",
    "In contrast, the scaled sd of our portfolio merchants have a very narrow distribution with median of 0.21, whilst the remaining merchants’ are much higher at 0.46.\n",
    "\n",
    "These cross sectional glimpses at statistics of the final portfolio indicate that the algorithm was successful in achieving the stability goal of high cashflow at low sd which gives high future benefit score for our portfolio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../plots/Boxplot_5V top100 vs 5V top100' Hist Mean(Revenue*Take Rate).png\" width=\"500\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../plots/Boxplot_5V top100 vs 5V top100' Hist Std Stdev(Revenue*Take Rate).png\" width=\"500\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also analysed the effectiveness of the last two features, by comparing our current top portfolio to a top portfolio ranked using a heuristic function of just the first three cashflow based features. \n",
    "\n",
    "We notice that, compared to the 3 featured portfolio, the 5 featured portfolio has more merchants with lower per order transaction amount, but also included some selected high per order amount merchants. This is the typical characteristic of a financial portfolio, with most merchants stable and some risky ones where risk is compensated by fair reward. This demonstrates that including repeated customer rate and persona score has enhanced our model. \n",
    "\n",
    "Overall, it can be seen that a portfolio most beneficial to stability and growth should contain a majority of merchants with small order quantity and low per order transaction amount, while having around 20% of high per order transaction amount merchants. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../plots/Histogram_3V top100 vs 5V top100 Mean Transaction Amount.png\" width=\"500\" class=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Result of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final tuned coefficients (after several rounds of tuning and refinement) to the heuristic linear function was:\n",
    "\n",
    "{60, -230000000, 105750000000, -6000000000, 602500000000}\n",
    "\n",
    "So the final heuristic function is:\n",
    "\n",
    "score of company = 60 * historic mean - 230000000 * standardised historic sd + 105750000000 * historic corr - 6000000000 loyalty + 602500000000 * persona score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommendation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we know that each variable was actualy useful?\n",
    "\n",
    "Because this is an unsupervised problem, we cannot do things such as AIC stepwise or feature selection F test to ensure the usefulness of each variable\n",
    "\n",
    "In training we tried ran the training process (combinations of each variable taking on values {0.0001, 0.01, 1, 100, 10000, -0.0001, -0.01, -1, -100, -10000} on just the first variable (historic mean revenue * take rate), then two variables (+ historic sd of revenue * take rate), then three variables (+ historic corr), then all 5 variables together, and each time we added more variables, we got to a higher validation sharpe ratios, meaning that the extra variables helped us distinguish companies that made the validation final portfolio better performing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a glimpse of our full dataset (i.e. features used for prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>n_periods</th>\n",
       "      <th>corr</th>\n",
       "      <th>repeated_purchase_rate</th>\n",
       "      <th>persona_score</th>\n",
       "      <th>standardised stdev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023283211</td>\n",
       "      <td>71944.954088</td>\n",
       "      <td>15268.757666</td>\n",
       "      <td>38</td>\n",
       "      <td>89865.793665</td>\n",
       "      <td>57655.593738</td>\n",
       "      <td>45527.819218</td>\n",
       "      <td>21222.833289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10142254217</td>\n",
       "      <td>22687.034837</td>\n",
       "      <td>6496.702667</td>\n",
       "      <td>38</td>\n",
       "      <td>80109.334092</td>\n",
       "      <td>56990.569906</td>\n",
       "      <td>47402.331867</td>\n",
       "      <td>28636.191172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10187291046</td>\n",
       "      <td>6831.716274</td>\n",
       "      <td>3379.999688</td>\n",
       "      <td>38</td>\n",
       "      <td>34995.557931</td>\n",
       "      <td>3484.320557</td>\n",
       "      <td>46658.738715</td>\n",
       "      <td>49475.118009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10192359162</td>\n",
       "      <td>40955.314495</td>\n",
       "      <td>17639.407542</td>\n",
       "      <td>38</td>\n",
       "      <td>47234.009458</td>\n",
       "      <td>3154.574132</td>\n",
       "      <td>60202.386586</td>\n",
       "      <td>43069.886679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10206519221</td>\n",
       "      <td>88038.400673</td>\n",
       "      <td>21292.527062</td>\n",
       "      <td>38</td>\n",
       "      <td>92172.605972</td>\n",
       "      <td>165604.172704</td>\n",
       "      <td>44677.257522</td>\n",
       "      <td>24185.499623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>99938978285</td>\n",
       "      <td>106551.591313</td>\n",
       "      <td>21699.148448</td>\n",
       "      <td>38</td>\n",
       "      <td>95903.180884</td>\n",
       "      <td>277847.759583</td>\n",
       "      <td>47348.625533</td>\n",
       "      <td>20364.921989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4363</th>\n",
       "      <td>99974311662</td>\n",
       "      <td>6326.735554</td>\n",
       "      <td>4783.350900</td>\n",
       "      <td>38</td>\n",
       "      <td>16927.146730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68106.927357</td>\n",
       "      <td>75605.355381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>99976658299</td>\n",
       "      <td>871306.137224</td>\n",
       "      <td>186985.910229</td>\n",
       "      <td>38</td>\n",
       "      <td>97885.491058</td>\n",
       "      <td>354736.454110</td>\n",
       "      <td>47225.595328</td>\n",
       "      <td>21460.414686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4365</th>\n",
       "      <td>99987905597</td>\n",
       "      <td>16290.096561</td>\n",
       "      <td>10052.773545</td>\n",
       "      <td>38</td>\n",
       "      <td>25886.462839</td>\n",
       "      <td>13071.895425</td>\n",
       "      <td>32046.388945</td>\n",
       "      <td>61710.951234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>99990536339</td>\n",
       "      <td>5328.961638</td>\n",
       "      <td>8906.929654</td>\n",
       "      <td>34</td>\n",
       "      <td>61329.622687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38365.036785</td>\n",
       "      <td>167141.936063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4367 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      merchant_abn           mean          stdev  n_periods          corr  \\\n",
       "0      10023283211   71944.954088   15268.757666         38  89865.793665   \n",
       "1      10142254217   22687.034837    6496.702667         38  80109.334092   \n",
       "2      10187291046    6831.716274    3379.999688         38  34995.557931   \n",
       "3      10192359162   40955.314495   17639.407542         38  47234.009458   \n",
       "4      10206519221   88038.400673   21292.527062         38  92172.605972   \n",
       "...            ...            ...            ...        ...           ...   \n",
       "4362   99938978285  106551.591313   21699.148448         38  95903.180884   \n",
       "4363   99974311662    6326.735554    4783.350900         38  16927.146730   \n",
       "4364   99976658299  871306.137224  186985.910229         38  97885.491058   \n",
       "4365   99987905597   16290.096561   10052.773545         38  25886.462839   \n",
       "4366   99990536339    5328.961638    8906.929654         34  61329.622687   \n",
       "\n",
       "      repeated_purchase_rate  persona_score  standardised stdev  \n",
       "0               57655.593738   45527.819218        21222.833289  \n",
       "1               56990.569906   47402.331867        28636.191172  \n",
       "2                3484.320557   46658.738715        49475.118009  \n",
       "3                3154.574132   60202.386586        43069.886679  \n",
       "4              165604.172704   44677.257522        24185.499623  \n",
       "...                      ...            ...                 ...  \n",
       "4362           277847.759583   47348.625533        20364.921989  \n",
       "4363                0.000000   68106.927357        75605.355381  \n",
       "4364           354736.454110   47225.595328        21460.414686  \n",
       "4365            13071.895425   32046.388945        61710.951234  \n",
       "4366                0.000000   38365.036785       167141.936063  \n",
       "\n",
       "[4367 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_overall = pd.read_csv('../data/curated/final_model/input/agg_fortnightly_mean_sd_marketcorr_NOFRAUD.csv')\n",
    "\n",
    "loyalty_overall = pd.read_csv(('../data/curated/final_model/input/loyalty_full.csv'))\n",
    "loyalty_overall = loyalty_overall[['merchant_abn', 'repeated_purchase_rate']]\n",
    "\n",
    "persona_overall = pd.read_csv(('../data/curated/final_model/input/persona_full.csv'))\n",
    "\n",
    "# merge dataset with 4th variable\n",
    "merchant_overall = merchant_overall.merge(loyalty_overall, on='merchant_abn', how='inner')\n",
    "merchant_overall = merchant_overall.merge(persona_overall, on='merchant_abn', how='inner')\n",
    "\n",
    "merchant_overall['standardised stdev'] = merchant_overall['stdev']/merchant_overall['mean']\n",
    "\n",
    "merchant_overall['corr'] = merchant_overall['corr'] * 100000\n",
    "merchant_overall['repeated_purchase_rate'] = merchant_overall['repeated_purchase_rate'] * 1000000\n",
    "merchant_overall['persona_score'] = merchant_overall['persona_score'] * 10000000\n",
    "\n",
    "merchant_overall['standardised stdev'] = merchant_overall['standardised stdev'] * 100000\n",
    "\n",
    "merchant_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 100 companies are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/curated/final_model/output/final_top100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = data.index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57564805948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31400548982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49465266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62789659343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99801770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10881038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49514806178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48549026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29215623643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>81548651453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89640578182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41001282470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>98671274602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37459245212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53877856360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21350600012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51527394775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50866797623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>89618228232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>88547577701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>30122382323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>61447419161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20562405782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>99776743787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33068332703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>91720867026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21359184622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31585975447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96880556465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>62224020443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>94472466107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34096466752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>68559320474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18158387243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35556933338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>80682333501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>27093785141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>70501974849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>68004106739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>29023134283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>79633007926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>93558142492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>40555823280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>90543168331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>25228131129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>80518954462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>58454491168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36196225600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>52065114842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>41974958954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    merchant_abn\n",
       "1    57564805948\n",
       "2    31400548982\n",
       "3    49465266764\n",
       "4    62789659343\n",
       "5    99801770627\n",
       "6    10881038707\n",
       "7    49514806178\n",
       "8    48549026640\n",
       "9    29215623643\n",
       "10   81548651453\n",
       "11   89640578182\n",
       "12   41001282470\n",
       "13   98671274602\n",
       "14   37459245212\n",
       "15   53877856360\n",
       "16   21350600012\n",
       "17   51527394775\n",
       "18   50866797623\n",
       "19   89618228232\n",
       "20   88547577701\n",
       "21   30122382323\n",
       "22   61447419161\n",
       "23   20562405782\n",
       "24   99776743787\n",
       "25   33068332703\n",
       "26   91720867026\n",
       "27   21359184622\n",
       "28   31585975447\n",
       "29   96880556465\n",
       "30   62224020443\n",
       "31   94472466107\n",
       "32   34096466752\n",
       "33   68559320474\n",
       "34   18158387243\n",
       "35   35556933338\n",
       "36   80682333501\n",
       "37   27093785141\n",
       "38   70501974849\n",
       "39   68004106739\n",
       "40   29023134283\n",
       "41   79633007926\n",
       "42   93558142492\n",
       "43   40555823280\n",
       "44   90543168331\n",
       "45   25228131129\n",
       "46   80518954462\n",
       "47   58454491168\n",
       "48   36196225600\n",
       "49   52065114842\n",
       "50   41974958954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>99976658299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>71961434094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>30214222203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>80779820715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>22059270846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>54550134954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>15560455575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>49322182190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>49212265466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71350572766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>22033359776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>96161808980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>67609108741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>56946407125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>80109801322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>19618998054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>32560075533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>52160665475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>96680767841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>37379915451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>73972053940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>29566626791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>11237511112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>81761494572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>25674631453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>74648589246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>90692244747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>34179569263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>76767266140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>75342681786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>51279178333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>87667432396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>33604812025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>13514558491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>10648956813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>89502033586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>50315283629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>81410315303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>54272781746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>83412691377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>21807339153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>23338656015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>17488304283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>79953723663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>66667026714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>41944909975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>67794222692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>26445720989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>52959528548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>35909341340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     merchant_abn\n",
       "51    99976658299\n",
       "52    71961434094\n",
       "53    30214222203\n",
       "54    80779820715\n",
       "55    22059270846\n",
       "56    54550134954\n",
       "57    15560455575\n",
       "58    49322182190\n",
       "59    49212265466\n",
       "60    71350572766\n",
       "61    22033359776\n",
       "62    96161808980\n",
       "63    67609108741\n",
       "64    56946407125\n",
       "65    80109801322\n",
       "66    19618998054\n",
       "67    32560075533\n",
       "68    52160665475\n",
       "69    96680767841\n",
       "70    37379915451\n",
       "71    73972053940\n",
       "72    29566626791\n",
       "73    11237511112\n",
       "74    81761494572\n",
       "75    25674631453\n",
       "76    74648589246\n",
       "77    90692244747\n",
       "78    34179569263\n",
       "79    76767266140\n",
       "80    75342681786\n",
       "81    51279178333\n",
       "82    87667432396\n",
       "83    33604812025\n",
       "84    13514558491\n",
       "85    10648956813\n",
       "86    89502033586\n",
       "87    50315283629\n",
       "88    81410315303\n",
       "89    54272781746\n",
       "90    83412691377\n",
       "91    21807339153\n",
       "92    23338656015\n",
       "93    17488304283\n",
       "94    79953723663\n",
       "95    66667026714\n",
       "96    41944909975\n",
       "97    67794222692\n",
       "98    26445720989\n",
       "99    52959528548\n",
       "100   35909341340"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data[['merchant_abn']].head(50))\n",
    "display(data[['merchant_abn']].tail(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the proportions of each segment in the final portfolio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0: Medium business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57564805948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31400548982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49465266764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62789659343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99801770627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10881038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49514806178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48549026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41001282470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>98671274602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   57564805948\n",
       "1   31400548982\n",
       "2   49465266764\n",
       "3   62789659343\n",
       "4   99801770627\n",
       "5   10881038707\n",
       "6   49514806178\n",
       "7   48549026640\n",
       "8   41001282470\n",
       "9   98671274602"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster0.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 1 Large business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89640578182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37459245212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91720867026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50866797623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30122382323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68559320474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61447419161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88547577701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94472466107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21359184622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   89640578182\n",
       "1   37459245212\n",
       "2   91720867026\n",
       "3   50866797623\n",
       "4   30122382323\n",
       "5   68559320474\n",
       "6   61447419161\n",
       "7   88547577701\n",
       "8   94472466107\n",
       "9   21359184622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster1.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 2: Small Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_abn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20562405782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33604812025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29566626791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74648589246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75342681786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79953723663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67202032418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67330176930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>99904689266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91848160033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merchant_abn\n",
       "0   20562405782\n",
       "1   33604812025\n",
       "2   29566626791\n",
       "3   74648589246\n",
       "4   75342681786\n",
       "5   79953723663\n",
       "6   67202032418\n",
       "7   67330176930\n",
       "8   99904689266\n",
       "9   91848160033"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/curated/final_model/final_10_cluster2.csv')[['merchant_abn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the proportions of each segment in the final portfolio, medium sized merchants made up the majority of the portfolio. \n",
    "\n",
    "<img src=\"../plots/pie.png\" width=\"1000\" class=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
